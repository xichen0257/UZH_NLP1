{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ML4NLP1\n",
        "## Starting Point for Exercise 1, part II\n",
        "\n",
        "This notebook is supposed to serve as a starting point and/or inspiration when starting exercise 1, part II.\n",
        "\n",
        "One of the goals of this exercise is o make you acquainted with **skorch**. You will probably need to consult the [documentation](https://skorch.readthedocs.io/en/stable/)."
      ],
      "metadata": {
        "id": "Q-2GcUhgB0S7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V920LTuiq40d"
      },
      "source": [
        "# Installing skorch and loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "utYcb97jq40t"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "# Installation on Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    subprocess.run(['python', '-m', 'pip', 'install', 'skorch'])\n",
        "except ImportError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WZ3Y_KHvq40x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from skorch import NeuralNetClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D9d6X0ZZq40z"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H55IvQdyq403"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import re\n",
        "import string\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAnY8yaDq400"
      },
      "source": [
        "## Training a classifier and making predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "!gdown 1QP6YuwdKFNUPpvhOaAcvv2Pcp4JMbIRs # x_train\n",
        "!gdown 1QVo7PZAdiZKzifK8kwhEr_umosiDCUx6 # x_test\n",
        "!gdown 1QbBeKcmG2ZyAEFB3AKGTgSWQ1YEMn2jl # y_train\n",
        "!gdown 1QaZj6bI7_78ymnN8IpSk4gVvg-C9fA6X # y_test"
      ],
      "metadata": {
        "id": "zWjt9xGoswAC",
        "outputId": "46c8cbaa-7e80-4542-a5b1-5f4ccd0c440c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QP6YuwdKFNUPpvhOaAcvv2Pcp4JMbIRs\n",
            "To: /content/x_train.txt\n",
            "100% 64.1M/64.1M [00:00<00:00, 167MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QVo7PZAdiZKzifK8kwhEr_umosiDCUx6\n",
            "To: /content/x_test.txt\n",
            "100% 65.2M/65.2M [00:00<00:00, 111MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QbBeKcmG2ZyAEFB3AKGTgSWQ1YEMn2jl\n",
            "To: /content/y_train.txt\n",
            "100% 480k/480k [00:00<00:00, 78.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QaZj6bI7_78ymnN8IpSk4gVvg-C9fA6X\n",
            "To: /content/y_test.txt\n",
            "100% 480k/480k [00:00<00:00, 37.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'x_train.txt') as f:\n",
        "    x_train = f.read().splitlines()\n",
        "with open(f'y_train.txt') as f:\n",
        "    y_train = f.read().splitlines()\n",
        "with open(f'x_test.txt') as f:\n",
        "    x_test = f.read().splitlines()\n",
        "with open(f'y_test.txt') as f:\n",
        "    y_test = f.read().splitlines()"
      ],
      "metadata": {
        "id": "-M6DgXdjtJyH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# combine x_train and y_train into one dataframe\n",
        "train_df = pd.DataFrame({'text': x_train, 'label': y_train})\n",
        "\n",
        "# combine x_test and y_test into one dataframe\n",
        "test_df = pd.DataFrame({'text': x_test, 'label': y_test})"
      ],
      "metadata": {
        "id": "oRqfDA9FuoX1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T: Please use again the train/test data that includes English, German, Dutch, Danish, Swedish and Norwegian, plus 20 additional languages of your choice (the labels can be found in the file labels.csv)\n",
        "# and adjust the train/test split if needed\n",
        "\n",
        "# Use again the labels selected in part1\n",
        "given_languages = ['eng', 'deu', 'nld', 'dan', 'swe', 'nno']\n",
        "\n",
        "additional_languages = ['ara', 'hak', 'lzh', 'tha', 'fra',\n",
        "                      'mal', 'zh-yue', 'zho', 'bar', 'tam',\n",
        "                      'tur', 'ukr', 'vie', 'cdo', 'ces',\n",
        "                      'div', 'ell', 'jpn', 'kor', 'lad']\n",
        "\n",
        "selected_languages = given_languages + additional_languages\n",
        "\n",
        "train_df_filtered = train_df[train_df['label'].isin(selected_languages)]\n",
        "test_df_filtered = test_df[test_df['label'].isin(selected_languages)]\n",
        "\n",
        "combined_df_filtered = pd.concat([train_df_filtered, test_df_filtered], axis=0)\n",
        "\n",
        "# check the size of training set and test set\n",
        "# print(len(train_df_filtered))\n",
        "# print(len(test_df_filtered))\n",
        "# print(len(combined_df_filtered))"
      ],
      "metadata": {
        "id": "r2cICoZ8xNMM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Adjust the data split into 80% training and 20% testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    combined_df_filtered['text'],\n",
        "    combined_df_filtered['label'],\n",
        "    test_size=0.2\n",
        ")\n",
        "\n",
        "# check the size of adjuested training set and test set\n",
        "# print(len(X_train))\n",
        "# print(len(Y_train))\n",
        "# print(len(X_test))\n",
        "# print(len(Y_test))"
      ],
      "metadata": {
        "id": "0vbeGQEnzYM2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T: use your adjusted code to encode the labels here\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "Y_train = le.fit_transform(Y_train)\n",
        "Y_test = le.transform(Y_test)\n",
        "\n",
        "# check if all the labels are corecyly encoded\n",
        "# print(np.unique(Y_train))\n",
        "# print(np.unique(Y_test))\n",
        "# print(Y_train.dtype)\n",
        "# print(Y_test.dtype)"
      ],
      "metadata": {
        "id": "PXpIOpjRxzTl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# T: In the following, you can find a small (almost) working example of a neural network. Unfortunately, again, the cat messed up some of the code. Please fix the code such that it is executable."
      ],
      "metadata": {
        "id": "212FI4CFFnrS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we extract some simple features as input for the neural network\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2), max_features=100, binary=True)\n",
        "\n",
        "# Vectorize X in to a sparse matrix\n",
        "X = vectorizer.fit_transform(X_train.to_numpy())"
      ],
      "metadata": {
        "id": "2-Ls0e0GQgMF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.astype(np.float32)\n",
        "y = Y_train.astype(np.int64)  # ready for NN training"
      ],
      "metadata": {
        "id": "URZTyQjJTQ5R"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMFoiitJq407"
      },
      "source": [
        "In the following, we define a vanilla neural network with two hidden layers. The output layer should have as many outputs as there are classes. In addition, it should have a nonlinearity function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierModule(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_units=200,\n",
        "            nonlin=F.relu,\n",
        "    ):\n",
        "        super(ClassifierModule, self).__init__()\n",
        "        self.num_units = num_units\n",
        "        self.nonlin = nonlin\n",
        "\n",
        "        self.dense0 = nn.Linear(100, num_units)\n",
        "        self.nonlin = nonlin\n",
        "        self.dense1 = nn.Linear(num_units, 50)\n",
        "        self.output = nn.Linear(50, 26)  # updated to the number of classes: 26\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "      X = self.nonlin(self.dense0(X))\n",
        "      X = F.relu(self.dense1(X))\n",
        "      X = self.output(X)\n",
        "      return X.squeeze(dim=1)"
      ],
      "metadata": {
        "id": "7Q5EDIGQUUBy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch.callbacks import EarlyStopping\n",
        "\n",
        "net = NeuralNetClassifier(\n",
        "    ClassifierModule,\n",
        "    max_epochs=20,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    lr=0.1,\n",
        "    # device='cuda',  # comment this to train with CPU\n",
        ")"
      ],
      "metadata": {
        "id": "wKnJECeQGpyI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.fit(X, y)"
      ],
      "metadata": {
        "id": "QcNOd9yBSxys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300b7fc3-d9da-43d5-c951-415b0d14d9f6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.9430\u001b[0m       \u001b[32m0.2820\u001b[0m        \u001b[35m2.5842\u001b[0m  3.2308\n",
            "      2        \u001b[36m2.1704\u001b[0m       \u001b[32m0.4635\u001b[0m        \u001b[35m1.7737\u001b[0m  3.1706\n",
            "      3        \u001b[36m1.5764\u001b[0m       \u001b[32m0.5488\u001b[0m        \u001b[35m1.3806\u001b[0m  1.9274\n",
            "      4        \u001b[36m1.2986\u001b[0m       \u001b[32m0.5882\u001b[0m        \u001b[35m1.2092\u001b[0m  1.8819\n",
            "      5        \u001b[36m1.1811\u001b[0m       \u001b[32m0.6099\u001b[0m        \u001b[35m1.1404\u001b[0m  1.9342\n",
            "      6        \u001b[36m1.1235\u001b[0m       \u001b[32m0.6190\u001b[0m        \u001b[35m1.1033\u001b[0m  1.9701\n",
            "      7        \u001b[36m1.0861\u001b[0m       \u001b[32m0.6269\u001b[0m        \u001b[35m1.0783\u001b[0m  2.1285\n",
            "      8        \u001b[36m1.0583\u001b[0m       \u001b[32m0.6334\u001b[0m        \u001b[35m1.0600\u001b[0m  2.6380\n",
            "      9        \u001b[36m1.0363\u001b[0m       \u001b[32m0.6356\u001b[0m        \u001b[35m1.0462\u001b[0m  2.6414\n",
            "     10        \u001b[36m1.0184\u001b[0m       \u001b[32m0.6382\u001b[0m        \u001b[35m1.0356\u001b[0m  1.9051\n",
            "     11        \u001b[36m1.0037\u001b[0m       \u001b[32m0.6397\u001b[0m        \u001b[35m1.0274\u001b[0m  1.8913\n",
            "     12        \u001b[36m0.9910\u001b[0m       \u001b[32m0.6433\u001b[0m        \u001b[35m1.0209\u001b[0m  1.9028\n",
            "     13        \u001b[36m0.9800\u001b[0m       0.6430        \u001b[35m1.0159\u001b[0m  2.4850\n",
            "     14        \u001b[36m0.9705\u001b[0m       0.6430        \u001b[35m1.0121\u001b[0m  2.2429\n",
            "     15        \u001b[36m0.9620\u001b[0m       0.6421        \u001b[35m1.0091\u001b[0m  1.8707\n",
            "     16        \u001b[36m0.9544\u001b[0m       \u001b[32m0.6438\u001b[0m        \u001b[35m1.0064\u001b[0m  1.8548\n",
            "     17        \u001b[36m0.9475\u001b[0m       0.6428        \u001b[35m1.0046\u001b[0m  1.9329\n",
            "     18        \u001b[36m0.9411\u001b[0m       0.6435        \u001b[35m1.0030\u001b[0m  1.8422\n",
            "     19        \u001b[36m0.9352\u001b[0m       0.6438        \u001b[35m1.0021\u001b[0m  2.2993\n",
            "     20        \u001b[36m0.9296\u001b[0m       \u001b[32m0.6454\u001b[0m        \u001b[35m1.0014\u001b[0m  2.3762\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=ClassifierModule(\n",
              "    (dense0): Linear(in_features=100, out_features=200, bias=True)\n",
              "    (dense1): Linear(in_features=200, out_features=50, bias=True)\n",
              "    (output): Linear(in_features=50, out_features=26, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_score = net.score(X, y)\n",
        "print(f\"Training accuracy: {train_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24uRNsy7Meda",
        "outputId": "2eb6a0de-2d07-49bb-f729-f11444ef68fc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare test set for testing the trained NN\n",
        "X_T = vectorizer.transform(X_test.to_numpy())\n",
        "X_T = X_T.astype(np.float32)\n",
        "y_t = Y_test.astype(np.int64)"
      ],
      "metadata": {
        "id": "CgCy20h9VpZW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = net.score(X_T, y_t)\n",
        "print(f\"Test accuracy: {test_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "659kyPSkVg2X",
        "outputId": "7f4d9d20-7b50-40fa-d80f-cb15e77e400a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2: Improving accuracy\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_V_b1XTRaPaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the training model above, we now try to improve the training and testing accuracy by tuning hyperparameters.   \n",
        "*   In the first part, we explore the importance of different parameters by mannually selecting values.  \n",
        "*   In the second part, we use GridSearchCV to find the best hyperparameter combination automatically.\n",
        "\n"
      ],
      "metadata": {
        "id": "4Nz8f6nfeCq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from skorch import NeuralNetClassifier\n",
        "from skorch.callbacks import EarlyStopping\n",
        "from sklearn.pipeline import Pipeline\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "2dAS8dmaTbCM"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###First try\n",
        " We expanded the number of hidden layer units to 300, and use tanh as the new nonlinear activation function.  \n",
        "Also, we use the new Adam optimizer and a smaller learning rate: 0.01."
      ],
      "metadata": {
        "id": "xAwQR6qggHf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierModule_1(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_units=300, # 200 to 300\n",
        "            nonlin=F.tanh, # F.relu to F.tanh\n",
        "    ):\n",
        "        super(ClassifierModule_1, self).__init__()\n",
        "        self.num_units = num_units\n",
        "        self.nonlin = nonlin\n",
        "\n",
        "        self.dense0 = nn.Linear(100, num_units)\n",
        "        self.nonlin = nonlin\n",
        "        self.dense1 = nn.Linear(num_units, 50)\n",
        "        self.output = nn.Linear(50, 26)\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "      X = self.nonlin(self.dense0(X))\n",
        "      X = F.relu(self.dense1(X))\n",
        "      X = self.output(X)\n",
        "      return X.squeeze(dim=1)"
      ],
      "metadata": {
        "id": "6AjpAxesava_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_1 = NeuralNetClassifier(\n",
        "    ClassifierModule_1,\n",
        "    max_epochs=20,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    optimizer=optim.Adam, #\n",
        "    lr=0.01, # 0.1 to 0.01\n",
        "    # device='cuda',  # comment this to train with CPU\n",
        ")"
      ],
      "metadata": {
        "id": "QNnSUcPba4KY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_1.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnrEkzXXbXUm",
        "outputId": "afc16eb7-abff-464b-fe33-4b5d15028a04"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5101\u001b[0m       \u001b[32m0.5702\u001b[0m        \u001b[35m1.2035\u001b[0m  2.0220\n",
            "      2        \u001b[36m1.0868\u001b[0m       \u001b[32m0.6139\u001b[0m        \u001b[35m1.0901\u001b[0m  2.0142\n",
            "      3        \u001b[36m1.0358\u001b[0m       \u001b[32m0.6197\u001b[0m        \u001b[35m1.0816\u001b[0m  2.5133\n",
            "      4        \u001b[36m0.9940\u001b[0m       0.6185        1.0871  2.4442\n",
            "      5        \u001b[36m0.9682\u001b[0m       \u001b[32m0.6288\u001b[0m        1.0894  1.9952\n",
            "      6        \u001b[36m0.9478\u001b[0m       \u001b[32m0.6296\u001b[0m        \u001b[35m1.0778\u001b[0m  1.9695\n",
            "      7        \u001b[36m0.9204\u001b[0m       0.6291        1.1016  2.9079\n",
            "      8        \u001b[36m0.9003\u001b[0m       0.6255        1.1018  2.3498\n",
            "      9        \u001b[36m0.8988\u001b[0m       0.6236        1.1388  2.8139\n",
            "     10        \u001b[36m0.8622\u001b[0m       \u001b[32m0.6317\u001b[0m        1.1325  1.9857\n",
            "     11        \u001b[36m0.8534\u001b[0m       0.6200        1.1964  2.0056\n",
            "     12        \u001b[36m0.8445\u001b[0m       \u001b[32m0.6325\u001b[0m        1.1820  1.9626\n",
            "     13        \u001b[36m0.8173\u001b[0m       0.6188        1.2477  1.9380\n",
            "     14        0.8345       0.6106        1.2479  2.3834\n",
            "     15        0.8372       0.6214        1.2427  2.5001\n",
            "     16        \u001b[36m0.8166\u001b[0m       0.6075        1.3066  1.9387\n",
            "     17        \u001b[36m0.8045\u001b[0m       0.6291        1.2619  1.9535\n",
            "     18        \u001b[36m0.7864\u001b[0m       0.6200        1.3363  1.9479\n",
            "     19        \u001b[36m0.7746\u001b[0m       0.6094        1.3647  2.0166\n",
            "     20        0.7769       0.6077        1.3838  2.6229\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=ClassifierModule_1(\n",
              "    (dense0): Linear(in_features=100, out_features=300, bias=True)\n",
              "    (dense1): Linear(in_features=300, out_features=50, bias=True)\n",
              "    (output): Linear(in_features=50, out_features=26, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_score = net_1.score(X, y)\n",
        "print(f\"Training accuracy: {train_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiOL-tjQcNYq",
        "outputId": "fae1fdd4-36d7-45e0-d0f1-dc47f0a212f6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = net_1.score(X_T, y_t)\n",
        "print(f\"Test accuracy: {test_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiRXHRVLcTcz",
        "outputId": "ec31b061-0f9e-48e5-cab5-59415b458b3b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Second try\n",
        "Compared to the first try, we use a even smaller learning rate: 0.005, and add the early stopping."
      ],
      "metadata": {
        "id": "it2q4N4dh_3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierModule_2(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_units=300,\n",
        "            nonlin=F.tanh,\n",
        "    ):\n",
        "        super(ClassifierModule_2, self).__init__()\n",
        "        self.num_units = num_units\n",
        "        self.nonlin = nonlin\n",
        "\n",
        "        self.dense0 = nn.Linear(100, num_units)\n",
        "        self.nonlin = nonlin\n",
        "        self.dense1 = nn.Linear(num_units, 50)\n",
        "        self.output = nn.Linear(50, 26)\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "      X = self.nonlin(self.dense0(X))\n",
        "      X = F.relu(self.dense1(X))\n",
        "      X = self.output(X)\n",
        "      return X.squeeze(dim=1)"
      ],
      "metadata": {
        "id": "V8RCajzEchxw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_2 = NeuralNetClassifier(\n",
        "    ClassifierModule_2,\n",
        "    max_epochs=20,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    optimizer=optim.Adam,\n",
        "    lr=0.005, # 0.01 to 0.005\n",
        "    callbacks=[EarlyStopping(patience=5)], # add early stopping condition\n",
        "    # device='cuda',  # comment this to train with CPU\n",
        ")"
      ],
      "metadata": {
        "id": "wBdKG5MZckva"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_2.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPT15Laecn7f",
        "outputId": "0db795c4-9b63-4de4-dddf-834a99072547"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5355\u001b[0m       \u001b[32m0.5889\u001b[0m        \u001b[35m1.1388\u001b[0m  2.0542\n",
            "      2        \u001b[36m1.0501\u001b[0m       \u001b[32m0.6317\u001b[0m        \u001b[35m1.0298\u001b[0m  2.1422\n",
            "      3        \u001b[36m0.9873\u001b[0m       \u001b[32m0.6334\u001b[0m        1.0312  2.1270\n",
            "      4        \u001b[36m0.9618\u001b[0m       0.6320        1.0345  2.2988\n",
            "      5        \u001b[36m0.9359\u001b[0m       0.6238        1.0644  2.6388\n",
            "      6        \u001b[36m0.9180\u001b[0m       \u001b[32m0.6358\u001b[0m        1.0584  1.9403\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=ClassifierModule_2(\n",
              "    (dense0): Linear(in_features=100, out_features=300, bias=True)\n",
              "    (dense1): Linear(in_features=300, out_features=50, bias=True)\n",
              "    (output): Linear(in_features=50, out_features=26, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_score = net_2.score(X, y)\n",
        "print(f\"Training accuracy: {train_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o_zeyxFdsHe",
        "outputId": "fd14dcb1-db13-464f-bec3-d685bf1d10a8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = net_2.score(X_T, y_t)\n",
        "print(f\"Test accuracy: {test_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ffd53a0-59f9-4fa6-b420-5df57febe85d",
        "id": "Ztk3hMOJcs5l"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Third try\n",
        "In this round, we try to replace the Adam optimizer with the SGD optimizer. We found that the accuracy was much lower after training, however there was an evident trend of growth. So we also increased the number of epochs and adjusted the early stopping patience accordingly.  \n",
        "Here we don't show the whole process of our exploration."
      ],
      "metadata": {
        "id": "2-Qxc_HSl2OS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierModule_3(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_units=300,\n",
        "            nonlin=F.tanh,\n",
        "    ):\n",
        "        super(ClassifierModule_3, self).__init__()\n",
        "        self.num_units = num_units\n",
        "        self.nonlin = nonlin\n",
        "\n",
        "        self.dense0 = nn.Linear(100, num_units)\n",
        "        self.nonlin = nonlin\n",
        "        self.dense1 = nn.Linear(num_units, 50)\n",
        "        self.output = nn.Linear(50, 26)\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "      X = self.nonlin(self.dense0(X))\n",
        "      X = F.relu(self.dense1(X))\n",
        "      X = self.output(X)\n",
        "      return X.squeeze(dim=1)"
      ],
      "metadata": {
        "id": "Tw5q5boil7tD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_3 = NeuralNetClassifier(\n",
        "    ClassifierModule_3,\n",
        "    max_epochs=200, # increase from 20 to 200\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    optimizer=optim.SGD, # Adam to SGD\n",
        "    lr=0.005,\n",
        "    callbacks=[EarlyStopping(patience=20)], # adjusted accordingly\n",
        "    # device='cuda',  # comment this to train with CPU\n",
        ")"
      ],
      "metadata": {
        "id": "bQg4WdvIl_YW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_3.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887a5f78-9d04-44fb-97ab-576a1969f001",
        "id": "k75NbKcgmFbE"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.2358\u001b[0m       \u001b[32m0.0423\u001b[0m        \u001b[35m3.2187\u001b[0m  1.9601\n",
            "      2        \u001b[36m3.1987\u001b[0m       \u001b[32m0.0560\u001b[0m        \u001b[35m3.1782\u001b[0m  2.8086\n",
            "      3        \u001b[36m3.1528\u001b[0m       \u001b[32m0.0716\u001b[0m        \u001b[35m3.1275\u001b[0m  1.9926\n",
            "      4        \u001b[36m3.0973\u001b[0m       \u001b[32m0.0901\u001b[0m        \u001b[35m3.0691\u001b[0m  1.8843\n",
            "      5        \u001b[36m3.0379\u001b[0m       \u001b[32m0.1474\u001b[0m        \u001b[35m3.0112\u001b[0m  1.9032\n",
            "      6        \u001b[36m2.9826\u001b[0m       \u001b[32m0.1962\u001b[0m        \u001b[35m2.9608\u001b[0m  1.8834\n",
            "      7        \u001b[36m2.9360\u001b[0m       \u001b[32m0.2385\u001b[0m        \u001b[35m2.9185\u001b[0m  1.8979\n",
            "      8        \u001b[36m2.8952\u001b[0m       \u001b[32m0.2683\u001b[0m        \u001b[35m2.8794\u001b[0m  2.7937\n",
            "      9        \u001b[36m2.8558\u001b[0m       \u001b[32m0.2892\u001b[0m        \u001b[35m2.8401\u001b[0m  1.9987\n",
            "     10        \u001b[36m2.8153\u001b[0m       \u001b[32m0.3394\u001b[0m        \u001b[35m2.7990\u001b[0m  1.9023\n",
            "     11        \u001b[36m2.7724\u001b[0m       \u001b[32m0.3675\u001b[0m        \u001b[35m2.7548\u001b[0m  1.8845\n",
            "     12        \u001b[36m2.7261\u001b[0m       \u001b[32m0.3865\u001b[0m        \u001b[35m2.7071\u001b[0m  1.9206\n",
            "     13        \u001b[36m2.6760\u001b[0m       \u001b[32m0.4026\u001b[0m        \u001b[35m2.6556\u001b[0m  1.9033\n",
            "     14        \u001b[36m2.6224\u001b[0m       \u001b[32m0.4132\u001b[0m        \u001b[35m2.6008\u001b[0m  2.8284\n",
            "     15        \u001b[36m2.5661\u001b[0m       \u001b[32m0.4236\u001b[0m        \u001b[35m2.5437\u001b[0m  1.9255\n",
            "     16        \u001b[36m2.5080\u001b[0m       \u001b[32m0.4276\u001b[0m        \u001b[35m2.4855\u001b[0m  1.9168\n",
            "     17        \u001b[36m2.4494\u001b[0m       \u001b[32m0.4332\u001b[0m        \u001b[35m2.4272\u001b[0m  1.9269\n",
            "     18        \u001b[36m2.3911\u001b[0m       \u001b[32m0.4392\u001b[0m        \u001b[35m2.3696\u001b[0m  1.9526\n",
            "     19        \u001b[36m2.3339\u001b[0m       \u001b[32m0.4442\u001b[0m        \u001b[35m2.3133\u001b[0m  1.9576\n",
            "     20        \u001b[36m2.2780\u001b[0m       \u001b[32m0.4457\u001b[0m        \u001b[35m2.2585\u001b[0m  4.1611\n",
            "     21        \u001b[36m2.2238\u001b[0m       \u001b[32m0.4546\u001b[0m        \u001b[35m2.2055\u001b[0m  3.7864\n",
            "     22        \u001b[36m2.1716\u001b[0m       \u001b[32m0.4601\u001b[0m        \u001b[35m2.1545\u001b[0m  3.3526\n",
            "     23        \u001b[36m2.1214\u001b[0m       \u001b[32m0.4611\u001b[0m        \u001b[35m2.1057\u001b[0m  4.1256\n",
            "     24        \u001b[36m2.0735\u001b[0m       \u001b[32m0.4666\u001b[0m        \u001b[35m2.0591\u001b[0m  3.2792\n",
            "     25        \u001b[36m2.0278\u001b[0m       \u001b[32m0.4716\u001b[0m        \u001b[35m2.0147\u001b[0m  1.9400\n",
            "     26        \u001b[36m1.9843\u001b[0m       \u001b[32m0.4721\u001b[0m        \u001b[35m1.9726\u001b[0m  1.9754\n",
            "     27        \u001b[36m1.9429\u001b[0m       \u001b[32m0.4750\u001b[0m        \u001b[35m1.9325\u001b[0m  1.9532\n",
            "     28        \u001b[36m1.9036\u001b[0m       \u001b[32m0.4781\u001b[0m        \u001b[35m1.8944\u001b[0m  2.3735\n",
            "     29        \u001b[36m1.8662\u001b[0m       \u001b[32m0.4791\u001b[0m        \u001b[35m1.8581\u001b[0m  2.3657\n",
            "     30        \u001b[36m1.8305\u001b[0m       \u001b[32m0.4837\u001b[0m        \u001b[35m1.8235\u001b[0m  1.9276\n",
            "     31        \u001b[36m1.7965\u001b[0m       \u001b[32m0.4863\u001b[0m        \u001b[35m1.7903\u001b[0m  1.9029\n",
            "     32        \u001b[36m1.7639\u001b[0m       \u001b[32m0.5243\u001b[0m        \u001b[35m1.7586\u001b[0m  4.0984\n",
            "     33        \u001b[36m1.7326\u001b[0m       \u001b[32m0.5274\u001b[0m        \u001b[35m1.7281\u001b[0m  5.8464\n",
            "     34        \u001b[36m1.7027\u001b[0m       \u001b[32m0.5286\u001b[0m        \u001b[35m1.6988\u001b[0m  3.6811\n",
            "     35        \u001b[36m1.6738\u001b[0m       \u001b[32m0.5308\u001b[0m        \u001b[35m1.6706\u001b[0m  1.9251\n",
            "     36        \u001b[36m1.6461\u001b[0m       \u001b[32m0.5320\u001b[0m        \u001b[35m1.6435\u001b[0m  1.9164\n",
            "     37        \u001b[36m1.6194\u001b[0m       \u001b[32m0.5361\u001b[0m        \u001b[35m1.6174\u001b[0m  2.8084\n",
            "     38        \u001b[36m1.5937\u001b[0m       \u001b[32m0.5382\u001b[0m        \u001b[35m1.5923\u001b[0m  1.8890\n",
            "     39        \u001b[36m1.5690\u001b[0m       \u001b[32m0.5399\u001b[0m        \u001b[35m1.5681\u001b[0m  1.9301\n",
            "     40        \u001b[36m1.5452\u001b[0m       \u001b[32m0.5411\u001b[0m        \u001b[35m1.5449\u001b[0m  1.8965\n",
            "     41        \u001b[36m1.5224\u001b[0m       \u001b[32m0.5428\u001b[0m        \u001b[35m1.5227\u001b[0m  1.9224\n",
            "     42        \u001b[36m1.5006\u001b[0m       \u001b[32m0.5457\u001b[0m        \u001b[35m1.5013\u001b[0m  1.8960\n",
            "     43        \u001b[36m1.4796\u001b[0m       \u001b[32m0.5478\u001b[0m        \u001b[35m1.4808\u001b[0m  2.7439\n",
            "     44        \u001b[36m1.4594\u001b[0m       \u001b[32m0.5483\u001b[0m        \u001b[35m1.4611\u001b[0m  1.9068\n",
            "     45        \u001b[36m1.4401\u001b[0m       \u001b[32m0.5502\u001b[0m        \u001b[35m1.4423\u001b[0m  1.9546\n",
            "     46        \u001b[36m1.4216\u001b[0m       \u001b[32m0.5543\u001b[0m        \u001b[35m1.4243\u001b[0m  1.9218\n",
            "     47        \u001b[36m1.4040\u001b[0m       \u001b[32m0.5553\u001b[0m        \u001b[35m1.4071\u001b[0m  1.8811\n",
            "     48        \u001b[36m1.3872\u001b[0m       \u001b[32m0.5579\u001b[0m        \u001b[35m1.3908\u001b[0m  1.9020\n",
            "     49        \u001b[36m1.3711\u001b[0m       \u001b[32m0.5582\u001b[0m        \u001b[35m1.3752\u001b[0m  2.8129\n",
            "     50        \u001b[36m1.3559\u001b[0m       \u001b[32m0.5733\u001b[0m        \u001b[35m1.3604\u001b[0m  1.9074\n",
            "     51        \u001b[36m1.3413\u001b[0m       \u001b[32m0.5817\u001b[0m        \u001b[35m1.3463\u001b[0m  1.9329\n",
            "     52        \u001b[36m1.3276\u001b[0m       \u001b[32m0.5834\u001b[0m        \u001b[35m1.3330\u001b[0m  1.9371\n",
            "     53        \u001b[36m1.3145\u001b[0m       \u001b[32m0.5849\u001b[0m        \u001b[35m1.3203\u001b[0m  1.9620\n",
            "     54        \u001b[36m1.3020\u001b[0m       \u001b[32m0.5877\u001b[0m        \u001b[35m1.3083\u001b[0m  1.9320\n",
            "     55        \u001b[36m1.2903\u001b[0m       \u001b[32m0.5889\u001b[0m        \u001b[35m1.2969\u001b[0m  3.1215\n",
            "     56        \u001b[36m1.2791\u001b[0m       \u001b[32m0.5928\u001b[0m        \u001b[35m1.2862\u001b[0m  3.2855\n",
            "     57        \u001b[36m1.2685\u001b[0m       0.5925        \u001b[35m1.2760\u001b[0m  1.9041\n",
            "     58        \u001b[36m1.2584\u001b[0m       \u001b[32m0.5969\u001b[0m        \u001b[35m1.2663\u001b[0m  1.9514\n",
            "     59        \u001b[36m1.2488\u001b[0m       \u001b[32m0.5978\u001b[0m        \u001b[35m1.2571\u001b[0m  1.9744\n",
            "     60        \u001b[36m1.2397\u001b[0m       \u001b[32m0.6014\u001b[0m        \u001b[35m1.2483\u001b[0m  2.8628\n",
            "     61        \u001b[36m1.2311\u001b[0m       \u001b[32m0.6038\u001b[0m        \u001b[35m1.2400\u001b[0m  1.9134\n",
            "     62        \u001b[36m1.2228\u001b[0m       \u001b[32m0.6041\u001b[0m        \u001b[35m1.2321\u001b[0m  1.9403\n",
            "     63        \u001b[36m1.2149\u001b[0m       0.6041        \u001b[35m1.2245\u001b[0m  1.9204\n",
            "     64        \u001b[36m1.2073\u001b[0m       \u001b[32m0.6065\u001b[0m        \u001b[35m1.2173\u001b[0m  1.9249\n",
            "     65        \u001b[36m1.2001\u001b[0m       \u001b[32m0.6075\u001b[0m        \u001b[35m1.2104\u001b[0m  3.0249\n",
            "     66        \u001b[36m1.1931\u001b[0m       \u001b[32m0.6079\u001b[0m        \u001b[35m1.2038\u001b[0m  2.6588\n",
            "     67        \u001b[36m1.1865\u001b[0m       0.6077        \u001b[35m1.1974\u001b[0m  2.0171\n",
            "     68        \u001b[36m1.1800\u001b[0m       \u001b[32m0.6087\u001b[0m        \u001b[35m1.1913\u001b[0m  5.5245\n",
            "     69        \u001b[36m1.1739\u001b[0m       \u001b[32m0.6113\u001b[0m        \u001b[35m1.1854\u001b[0m  2.6590\n",
            "     70        \u001b[36m1.1680\u001b[0m       \u001b[32m0.6135\u001b[0m        \u001b[35m1.1798\u001b[0m  2.4685\n",
            "     71        \u001b[36m1.1623\u001b[0m       \u001b[32m0.6151\u001b[0m        \u001b[35m1.1745\u001b[0m  2.4324\n",
            "     72        \u001b[36m1.1568\u001b[0m       0.6142        \u001b[35m1.1693\u001b[0m  2.6836\n",
            "     73        \u001b[36m1.1516\u001b[0m       0.6149        \u001b[35m1.1643\u001b[0m  1.9861\n",
            "     74        \u001b[36m1.1465\u001b[0m       0.6151        \u001b[35m1.1595\u001b[0m  2.0807\n",
            "     75        \u001b[36m1.1416\u001b[0m       \u001b[32m0.6168\u001b[0m        \u001b[35m1.1549\u001b[0m  2.7660\n",
            "     76        \u001b[36m1.1369\u001b[0m       \u001b[32m0.6175\u001b[0m        \u001b[35m1.1505\u001b[0m  1.9451\n",
            "     77        \u001b[36m1.1324\u001b[0m       \u001b[32m0.6183\u001b[0m        \u001b[35m1.1462\u001b[0m  1.9590\n",
            "     78        \u001b[36m1.1280\u001b[0m       \u001b[32m0.6185\u001b[0m        \u001b[35m1.1421\u001b[0m  1.9262\n",
            "     79        \u001b[36m1.1237\u001b[0m       \u001b[32m0.6197\u001b[0m        \u001b[35m1.1382\u001b[0m  1.9490\n",
            "     80        \u001b[36m1.1196\u001b[0m       \u001b[32m0.6202\u001b[0m        \u001b[35m1.1344\u001b[0m  2.0940\n",
            "     81        \u001b[36m1.1157\u001b[0m       \u001b[32m0.6209\u001b[0m        \u001b[35m1.1307\u001b[0m  2.6619\n",
            "     82        \u001b[36m1.1118\u001b[0m       \u001b[32m0.6212\u001b[0m        \u001b[35m1.1272\u001b[0m  1.9423\n",
            "     83        \u001b[36m1.1081\u001b[0m       \u001b[32m0.6216\u001b[0m        \u001b[35m1.1238\u001b[0m  1.9737\n",
            "     84        \u001b[36m1.1046\u001b[0m       \u001b[32m0.6240\u001b[0m        \u001b[35m1.1205\u001b[0m  1.9570\n",
            "     85        \u001b[36m1.1011\u001b[0m       \u001b[32m0.6248\u001b[0m        \u001b[35m1.1174\u001b[0m  1.9315\n",
            "     86        \u001b[36m1.0978\u001b[0m       \u001b[32m0.6269\u001b[0m        \u001b[35m1.1143\u001b[0m  2.2351\n",
            "     87        \u001b[36m1.0945\u001b[0m       \u001b[32m0.6279\u001b[0m        \u001b[35m1.1114\u001b[0m  2.5725\n",
            "     88        \u001b[36m1.0914\u001b[0m       0.6279        \u001b[35m1.1086\u001b[0m  1.9914\n",
            "     89        \u001b[36m1.0883\u001b[0m       \u001b[32m0.6284\u001b[0m        \u001b[35m1.1058\u001b[0m  1.9022\n",
            "     90        \u001b[36m1.0854\u001b[0m       0.6281        \u001b[35m1.1032\u001b[0m  1.9066\n",
            "     91        \u001b[36m1.0825\u001b[0m       0.6284        \u001b[35m1.1006\u001b[0m  1.9244\n",
            "     92        \u001b[36m1.0797\u001b[0m       \u001b[32m0.6296\u001b[0m        \u001b[35m1.0981\u001b[0m  2.2124\n",
            "     93        \u001b[36m1.0770\u001b[0m       0.6296        \u001b[35m1.0957\u001b[0m  2.5262\n",
            "     94        \u001b[36m1.0743\u001b[0m       \u001b[32m0.6305\u001b[0m        \u001b[35m1.0934\u001b[0m  1.9100\n",
            "     95        \u001b[36m1.0718\u001b[0m       \u001b[32m0.6317\u001b[0m        \u001b[35m1.0912\u001b[0m  1.8968\n",
            "     96        \u001b[36m1.0693\u001b[0m       0.6317        \u001b[35m1.0890\u001b[0m  1.8907\n",
            "     97        \u001b[36m1.0669\u001b[0m       0.6317        \u001b[35m1.0869\u001b[0m  1.9188\n",
            "     98        \u001b[36m1.0645\u001b[0m       \u001b[32m0.6332\u001b[0m        \u001b[35m1.0848\u001b[0m  2.2075\n",
            "     99        \u001b[36m1.0622\u001b[0m       \u001b[32m0.6337\u001b[0m        \u001b[35m1.0828\u001b[0m  2.5895\n",
            "    100        \u001b[36m1.0599\u001b[0m       0.6337        \u001b[35m1.0809\u001b[0m  1.9140\n",
            "    101        \u001b[36m1.0577\u001b[0m       0.6334        \u001b[35m1.0790\u001b[0m  1.9179\n",
            "    102        \u001b[36m1.0555\u001b[0m       0.6337        \u001b[35m1.0772\u001b[0m  1.9141\n",
            "    103        \u001b[36m1.0534\u001b[0m       \u001b[32m0.6346\u001b[0m        \u001b[35m1.0754\u001b[0m  2.6604\n",
            "    104        \u001b[36m1.0514\u001b[0m       \u001b[32m0.6351\u001b[0m        \u001b[35m1.0737\u001b[0m  2.6252\n",
            "    105        \u001b[36m1.0494\u001b[0m       \u001b[32m0.6358\u001b[0m        \u001b[35m1.0720\u001b[0m  2.0983\n",
            "    106        \u001b[36m1.0474\u001b[0m       \u001b[32m0.6368\u001b[0m        \u001b[35m1.0704\u001b[0m  1.9137\n",
            "    107        \u001b[36m1.0455\u001b[0m       \u001b[32m0.6387\u001b[0m        \u001b[35m1.0688\u001b[0m  1.9497\n",
            "    108        \u001b[36m1.0436\u001b[0m       \u001b[32m0.6389\u001b[0m        \u001b[35m1.0672\u001b[0m  1.9615\n",
            "    109        \u001b[36m1.0418\u001b[0m       0.6385        \u001b[35m1.0657\u001b[0m  1.9770\n",
            "    110        \u001b[36m1.0400\u001b[0m       \u001b[32m0.6392\u001b[0m        \u001b[35m1.0642\u001b[0m  2.7165\n",
            "    111        \u001b[36m1.0382\u001b[0m       0.6392        \u001b[35m1.0628\u001b[0m  1.9902\n",
            "    112        \u001b[36m1.0365\u001b[0m       0.6389        \u001b[35m1.0614\u001b[0m  1.9417\n",
            "    113        \u001b[36m1.0348\u001b[0m       \u001b[32m0.6394\u001b[0m        \u001b[35m1.0600\u001b[0m  2.0538\n",
            "    114        \u001b[36m1.0331\u001b[0m       0.6380        \u001b[35m1.0587\u001b[0m  1.9853\n",
            "    115        \u001b[36m1.0315\u001b[0m       0.6380        \u001b[35m1.0574\u001b[0m  2.0114\n",
            "    116        \u001b[36m1.0299\u001b[0m       0.6377        \u001b[35m1.0561\u001b[0m  4.2620\n",
            "    117        \u001b[36m1.0283\u001b[0m       0.6377        \u001b[35m1.0548\u001b[0m  2.5230\n",
            "    118        \u001b[36m1.0268\u001b[0m       0.6394        \u001b[35m1.0536\u001b[0m  2.9821\n",
            "    119        \u001b[36m1.0253\u001b[0m       \u001b[32m0.6401\u001b[0m        \u001b[35m1.0525\u001b[0m  3.4839\n",
            "    120        \u001b[36m1.0238\u001b[0m       \u001b[32m0.6404\u001b[0m        \u001b[35m1.0513\u001b[0m  3.7411\n",
            "    121        \u001b[36m1.0223\u001b[0m       0.6404        \u001b[35m1.0502\u001b[0m  2.8300\n",
            "    122        \u001b[36m1.0209\u001b[0m       \u001b[32m0.6409\u001b[0m        \u001b[35m1.0491\u001b[0m  2.4701\n",
            "    123        \u001b[36m1.0195\u001b[0m       0.6406        \u001b[35m1.0480\u001b[0m  2.3615\n",
            "    124        \u001b[36m1.0181\u001b[0m       0.6409        \u001b[35m1.0469\u001b[0m  3.9707\n",
            "    125        \u001b[36m1.0168\u001b[0m       \u001b[32m0.6416\u001b[0m        \u001b[35m1.0459\u001b[0m  2.6789\n",
            "    126        \u001b[36m1.0155\u001b[0m       0.6413        \u001b[35m1.0449\u001b[0m  2.4828\n",
            "    127        \u001b[36m1.0142\u001b[0m       0.6413        \u001b[35m1.0439\u001b[0m  2.7535\n",
            "    128        \u001b[36m1.0129\u001b[0m       0.6413        \u001b[35m1.0430\u001b[0m  3.8070\n",
            "    129        \u001b[36m1.0116\u001b[0m       0.6416        \u001b[35m1.0420\u001b[0m  3.0141\n",
            "    130        \u001b[36m1.0104\u001b[0m       0.6416        \u001b[35m1.0411\u001b[0m  2.8383\n",
            "    131        \u001b[36m1.0092\u001b[0m       0.6413        \u001b[35m1.0402\u001b[0m  2.7521\n",
            "    132        \u001b[36m1.0080\u001b[0m       0.6411        \u001b[35m1.0394\u001b[0m  3.2535\n",
            "    133        \u001b[36m1.0068\u001b[0m       0.6413        \u001b[35m1.0385\u001b[0m  2.9322\n",
            "    134        \u001b[36m1.0056\u001b[0m       \u001b[32m0.6430\u001b[0m        \u001b[35m1.0377\u001b[0m  2.9828\n",
            "    135        \u001b[36m1.0045\u001b[0m       \u001b[32m0.6435\u001b[0m        \u001b[35m1.0368\u001b[0m  3.0964\n",
            "    136        \u001b[36m1.0033\u001b[0m       \u001b[32m0.6438\u001b[0m        \u001b[35m1.0360\u001b[0m  3.5588\n",
            "    137        \u001b[36m1.0022\u001b[0m       \u001b[32m0.6442\u001b[0m        \u001b[35m1.0353\u001b[0m  2.7777\n",
            "    138        \u001b[36m1.0011\u001b[0m       0.6442        \u001b[35m1.0345\u001b[0m  2.5838\n",
            "    139        \u001b[36m1.0001\u001b[0m       0.6440        \u001b[35m1.0337\u001b[0m  2.8949\n",
            "    140        \u001b[36m0.9990\u001b[0m       0.6440        \u001b[35m1.0330\u001b[0m  2.0694\n",
            "    141        \u001b[36m0.9980\u001b[0m       \u001b[32m0.6445\u001b[0m        \u001b[35m1.0323\u001b[0m  2.7989\n",
            "    142        \u001b[36m0.9970\u001b[0m       0.6445        \u001b[35m1.0316\u001b[0m  1.9649\n",
            "    143        \u001b[36m0.9959\u001b[0m       \u001b[32m0.6447\u001b[0m        \u001b[35m1.0309\u001b[0m  2.9657\n",
            "    144        \u001b[36m0.9949\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m1.0302\u001b[0m  2.9592\n",
            "    145        \u001b[36m0.9940\u001b[0m       \u001b[32m0.6452\u001b[0m        \u001b[35m1.0296\u001b[0m  2.7426\n",
            "    146        \u001b[36m0.9930\u001b[0m       \u001b[32m0.6454\u001b[0m        \u001b[35m1.0289\u001b[0m  3.5111\n",
            "    147        \u001b[36m0.9920\u001b[0m       \u001b[32m0.6457\u001b[0m        \u001b[35m1.0283\u001b[0m  2.5871\n",
            "    148        \u001b[36m0.9911\u001b[0m       \u001b[32m0.6459\u001b[0m        \u001b[35m1.0277\u001b[0m  2.4875\n",
            "    149        \u001b[36m0.9902\u001b[0m       0.6459        \u001b[35m1.0271\u001b[0m  1.9418\n",
            "    150        \u001b[36m0.9892\u001b[0m       \u001b[32m0.6462\u001b[0m        \u001b[35m1.0265\u001b[0m  2.3782\n",
            "    151        \u001b[36m0.9883\u001b[0m       0.6462        \u001b[35m1.0259\u001b[0m  2.4026\n",
            "    152        \u001b[36m0.9874\u001b[0m       \u001b[32m0.6464\u001b[0m        \u001b[35m1.0253\u001b[0m  2.6271\n",
            "    153        \u001b[36m0.9866\u001b[0m       0.6464        \u001b[35m1.0247\u001b[0m  2.5222\n",
            "    154        \u001b[36m0.9857\u001b[0m       0.6462        \u001b[35m1.0242\u001b[0m  2.4171\n",
            "    155        \u001b[36m0.9848\u001b[0m       0.6462        \u001b[35m1.0237\u001b[0m  3.9500\n",
            "    156        \u001b[36m0.9840\u001b[0m       0.6462        \u001b[35m1.0231\u001b[0m  2.8328\n",
            "    157        \u001b[36m0.9831\u001b[0m       \u001b[32m0.6466\u001b[0m        \u001b[35m1.0226\u001b[0m  3.6117\n",
            "    158        \u001b[36m0.9823\u001b[0m       0.6464        \u001b[35m1.0221\u001b[0m  3.1795\n",
            "    159        \u001b[36m0.9815\u001b[0m       0.6464        \u001b[35m1.0216\u001b[0m  4.5521\n",
            "    160        \u001b[36m0.9807\u001b[0m       0.6462        \u001b[35m1.0211\u001b[0m  4.1015\n",
            "    161        \u001b[36m0.9799\u001b[0m       0.6466        \u001b[35m1.0206\u001b[0m  2.9121\n",
            "    162        \u001b[36m0.9791\u001b[0m       0.6464        \u001b[35m1.0201\u001b[0m  3.2217\n",
            "    163        \u001b[36m0.9783\u001b[0m       0.6466        \u001b[35m1.0196\u001b[0m  3.5174\n",
            "    164        \u001b[36m0.9775\u001b[0m       \u001b[32m0.6469\u001b[0m        \u001b[35m1.0192\u001b[0m  2.8389\n",
            "    165        \u001b[36m0.9768\u001b[0m       0.6466        \u001b[35m1.0187\u001b[0m  2.5512\n",
            "    166        \u001b[36m0.9760\u001b[0m       0.6464        \u001b[35m1.0182\u001b[0m  3.7001\n",
            "    167        \u001b[36m0.9753\u001b[0m       \u001b[32m0.6474\u001b[0m        \u001b[35m1.0178\u001b[0m  2.8579\n",
            "    168        \u001b[36m0.9745\u001b[0m       0.6474        \u001b[35m1.0174\u001b[0m  2.5765\n",
            "    169        \u001b[36m0.9738\u001b[0m       0.6474        \u001b[35m1.0169\u001b[0m  2.5418\n",
            "    170        \u001b[36m0.9731\u001b[0m       \u001b[32m0.6476\u001b[0m        \u001b[35m1.0165\u001b[0m  3.2743\n",
            "    171        \u001b[36m0.9724\u001b[0m       \u001b[32m0.6478\u001b[0m        \u001b[35m1.0161\u001b[0m  2.9380\n",
            "    172        \u001b[36m0.9717\u001b[0m       0.6476        \u001b[35m1.0157\u001b[0m  1.9268\n",
            "    173        \u001b[36m0.9710\u001b[0m       0.6476        \u001b[35m1.0153\u001b[0m  1.8983\n",
            "    174        \u001b[36m0.9703\u001b[0m       0.6478        \u001b[35m1.0149\u001b[0m  2.2747\n",
            "    175        \u001b[36m0.9696\u001b[0m       0.6478        \u001b[35m1.0145\u001b[0m  3.2048\n",
            "    176        \u001b[36m0.9690\u001b[0m       0.6478        \u001b[35m1.0142\u001b[0m  3.4590\n",
            "    177        \u001b[36m0.9683\u001b[0m       0.6466        \u001b[35m1.0138\u001b[0m  1.8509\n",
            "    178        \u001b[36m0.9676\u001b[0m       0.6464        \u001b[35m1.0134\u001b[0m  1.9158\n",
            "    179        \u001b[36m0.9670\u001b[0m       0.6459        \u001b[35m1.0131\u001b[0m  1.8754\n",
            "    180        \u001b[36m0.9664\u001b[0m       0.6464        \u001b[35m1.0127\u001b[0m  1.8951\n",
            "    181        \u001b[36m0.9657\u001b[0m       0.6462        \u001b[35m1.0124\u001b[0m  2.7830\n",
            "    182        \u001b[36m0.9651\u001b[0m       0.6464        \u001b[35m1.0120\u001b[0m  2.7398\n",
            "    183        \u001b[36m0.9645\u001b[0m       0.6464        \u001b[35m1.0117\u001b[0m  2.5806\n",
            "    184        \u001b[36m0.9639\u001b[0m       0.6469        \u001b[35m1.0114\u001b[0m  2.6610\n",
            "    185        \u001b[36m0.9633\u001b[0m       0.6471        \u001b[35m1.0110\u001b[0m  3.1661\n",
            "    186        \u001b[36m0.9627\u001b[0m       0.6469        \u001b[35m1.0107\u001b[0m  3.4342\n",
            "    187        \u001b[36m0.9621\u001b[0m       0.6466        \u001b[35m1.0104\u001b[0m  2.6008\n",
            "    188        \u001b[36m0.9615\u001b[0m       0.6466        \u001b[35m1.0101\u001b[0m  2.8670\n",
            "    189        \u001b[36m0.9609\u001b[0m       0.6466        \u001b[35m1.0098\u001b[0m  2.5078\n",
            "    190        \u001b[36m0.9603\u001b[0m       0.6466        \u001b[35m1.0095\u001b[0m  3.5369\n",
            "    191        \u001b[36m0.9597\u001b[0m       0.6469        \u001b[35m1.0092\u001b[0m  2.7690\n",
            "    192        \u001b[36m0.9592\u001b[0m       0.6469        \u001b[35m1.0089\u001b[0m  2.8120\n",
            "    193        \u001b[36m0.9586\u001b[0m       0.6469        \u001b[35m1.0086\u001b[0m  2.5798\n",
            "    194        \u001b[36m0.9581\u001b[0m       0.6469        \u001b[35m1.0083\u001b[0m  5.4276\n",
            "    195        \u001b[36m0.9575\u001b[0m       0.6471        \u001b[35m1.0080\u001b[0m  2.9802\n",
            "    196        \u001b[36m0.9570\u001b[0m       0.6474        \u001b[35m1.0078\u001b[0m  3.2302\n",
            "    197        \u001b[36m0.9564\u001b[0m       0.6478        \u001b[35m1.0075\u001b[0m  6.4555\n",
            "    198        \u001b[36m0.9559\u001b[0m       0.6476        \u001b[35m1.0072\u001b[0m  4.5339\n",
            "    199        \u001b[36m0.9553\u001b[0m       0.6478        \u001b[35m1.0070\u001b[0m  7.1776\n",
            "    200        \u001b[36m0.9548\u001b[0m       0.6476        \u001b[35m1.0067\u001b[0m  2.6802\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=ClassifierModule_3(\n",
              "    (dense0): Linear(in_features=100, out_features=300, bias=True)\n",
              "    (dense1): Linear(in_features=300, out_features=50, bias=True)\n",
              "    (output): Linear(in_features=50, out_features=26, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_score = net_3.score(X, y)\n",
        "print(f\"Training accuracy: {train_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d89b0629-ed53-43fb-f136-5c67ff29957c",
        "id": "tFYADZzimD1k"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = net_3.score(X_T, y_t)\n",
        "print(f\"Test accuracy: {test_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c76a6ddf-4417-47bd-e3c6-46aaec71428a",
        "id": "sSQLW_mOmB9G"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, there is no obvious improvement of accuracy compared to using the Adam optimizer."
      ],
      "metadata": {
        "id": "2aF7zJp9yFhY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fourth try"
      ],
      "metadata": {
        "id": "r-k2F_nO0AUo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this round, we try a new nonlinear activation function: sigmoid.  \n",
        "The tuning process of other parameters combined with sigmoid is not completely presented here. When the accuracy obtained under multiple parameter combinations is not very different, we arbitrarily choose one as the final presentation."
      ],
      "metadata": {
        "id": "lyGfRCab_2jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierModule_4(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_units=300,\n",
        "            nonlin=F.sigmoid, #\n",
        "    ):\n",
        "        super(ClassifierModule_4, self).__init__()\n",
        "        self.num_units = num_units\n",
        "        self.nonlin = nonlin\n",
        "\n",
        "        self.dense0 = nn.Linear(100, num_units)\n",
        "        self.nonlin = nonlin\n",
        "        self.dense1 = nn.Linear(num_units, 50)\n",
        "        self.output = nn.Linear(50, 26)\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "      X = self.nonlin(self.dense0(X))\n",
        "      X = F.relu(self.dense1(X))\n",
        "      X = self.output(X)\n",
        "      return X.squeeze(dim=1)"
      ],
      "metadata": {
        "id": "jd5DqVZxz_M0"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_4 = NeuralNetClassifier(\n",
        "    ClassifierModule_4,\n",
        "    max_epochs=20,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    optimizer=optim.Adam,\n",
        "    lr=0.01\n",
        "    # callbacks=[EarlyStopping(patience=5)],#\n",
        "    # device='cuda',  # comment this to train with CPU\n",
        ")"
      ],
      "metadata": {
        "id": "cYbZAo9qz9gg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_4.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50MqiZEfz6jD",
        "outputId": "705fc81d-614e-45a7-cb1d-f4c338ea88d5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.3922\u001b[0m       \u001b[32m0.4267\u001b[0m        \u001b[35m1.6573\u001b[0m  2.9829\n",
            "      2        \u001b[36m1.4156\u001b[0m       \u001b[32m0.5329\u001b[0m        \u001b[35m1.2848\u001b[0m  2.6766\n",
            "      3        \u001b[36m1.2049\u001b[0m       \u001b[32m0.5832\u001b[0m        \u001b[35m1.1973\u001b[0m  2.2800\n",
            "      4        \u001b[36m1.1340\u001b[0m       \u001b[32m0.5938\u001b[0m        \u001b[35m1.1609\u001b[0m  2.1023\n",
            "      5        \u001b[36m1.0850\u001b[0m       \u001b[32m0.6029\u001b[0m        \u001b[35m1.1405\u001b[0m  1.9761\n",
            "      6        \u001b[36m1.0481\u001b[0m       \u001b[32m0.6091\u001b[0m        \u001b[35m1.1203\u001b[0m  2.0462\n",
            "      7        \u001b[36m1.0170\u001b[0m       \u001b[32m0.6188\u001b[0m        \u001b[35m1.1041\u001b[0m  2.1022\n",
            "      8        \u001b[36m0.9882\u001b[0m       \u001b[32m0.6216\u001b[0m        \u001b[35m1.0955\u001b[0m  3.9923\n",
            "      9        \u001b[36m0.9642\u001b[0m       \u001b[32m0.6252\u001b[0m        \u001b[35m1.0903\u001b[0m  2.1661\n",
            "     10        \u001b[36m0.9420\u001b[0m       \u001b[32m0.6262\u001b[0m        1.0905  2.0745\n",
            "     11        \u001b[36m0.9213\u001b[0m       \u001b[32m0.6267\u001b[0m        1.0947  3.1028\n",
            "     12        \u001b[36m0.8999\u001b[0m       0.6255        1.1059  4.5423\n",
            "     13        \u001b[36m0.8831\u001b[0m       \u001b[32m0.6272\u001b[0m        1.1154  3.5566\n",
            "     14        \u001b[36m0.8680\u001b[0m       0.6250        1.1236  2.9493\n",
            "     15        \u001b[36m0.8541\u001b[0m       \u001b[32m0.6274\u001b[0m        1.1429  3.4933\n",
            "     16        \u001b[36m0.8376\u001b[0m       0.6233        1.1839  3.6687\n",
            "     17        \u001b[36m0.8258\u001b[0m       0.6180        1.2136  3.0078\n",
            "     18        \u001b[36m0.8180\u001b[0m       0.6060        1.2594  3.3072\n",
            "     19        \u001b[36m0.8091\u001b[0m       0.6142        1.2167  3.5245\n",
            "     20        \u001b[36m0.8047\u001b[0m       0.6267        1.1952  4.0274\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=ClassifierModule_4(\n",
              "    (dense0): Linear(in_features=100, out_features=300, bias=True)\n",
              "    (dense1): Linear(in_features=300, out_features=50, bias=True)\n",
              "    (output): Linear(in_features=50, out_features=26, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_score = net_4.score(X, y)\n",
        "print(f\"Training accuracy: {train_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPpH1GbOz5CH",
        "outputId": "26d815dc-064c-4c87-d5f6-faefb0d25d16"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_score = net_4.score(X_T, y_t)\n",
        "print(f\"Test accuracy: {test_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpHOAwdwyeCw",
        "outputId": "b33c26ad-399c-4846-f1a5-1bda0ef33816"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy of sigmoid is even worse. Therefore, we don't include sigmoid as an option of activation function in the following grid search experiment."
      ],
      "metadata": {
        "id": "Z0eIZJlp5qEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Grid Search"
      ],
      "metadata": {
        "id": "FFGQYG-basIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In former experiments, there are not obvious improvement of accuracy when we tune some parameters. So now we use grid search to find the best combination of these parameters."
      ],
      "metadata": {
        "id": "Vz7wJdD7iAxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Redifine NN for GridSearch\n",
        "class ClassifierModule_grid(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_units=200,\n",
        "            nonlin=F.relu,\n",
        "    ):\n",
        "        super(ClassifierModule_grid, self).__init__()\n",
        "        self.num_units = num_units\n",
        "        self.nonlin = nonlin\n",
        "\n",
        "        self.dense0 = nn.Linear(100, num_units)\n",
        "        self.nonlin = nonlin\n",
        "        self.dense1 = nn.Linear(num_units, 50)\n",
        "        self.output = nn.Linear(50, 26)\n",
        "\n",
        "    def forward(self, X, **kwargs):\n",
        "      X = self.nonlin(self.dense0(X))\n",
        "      X = F.relu(self.dense1(X))\n",
        "      X = self.output(X)\n",
        "      return X.squeeze(dim=1)"
      ],
      "metadata": {
        "id": "fHcYOl1t4SCu"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch.callbacks import EarlyStopping\n",
        "\n",
        "net_grid = NeuralNetClassifier(\n",
        "    ClassifierModule_grid,\n",
        "    max_epochs=20,\n",
        "    criterion=nn.CrossEntropyLoss(),\n",
        "    lr=0.1,\n",
        "    callbacks=[EarlyStopping(patience=5)], # adjusted accordingly\n",
        "    # device='cuda',  # comment this to train with CPU\n",
        ")"
      ],
      "metadata": {
        "id": "-MJTzSpM4Uco"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to adjust datatype before NN\n",
        "def type_adjust(a):\n",
        "  a = a.astype(np.float32)\n",
        "  return a"
      ],
      "metadata": {
        "id": "Qsrt3lkc3u16"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct pipeline\n",
        "pipeline = Pipeline(\n",
        "    [\n",
        "        ('vect', CountVectorizer(analyzer='char', max_features=100, binary=True)),\n",
        "        ('adjust_datatype', FunctionTransformer(func=type_adjust, validate=False)),\n",
        "        ('clf', net_grid),\n",
        "    ]\n",
        ")\n",
        "\n",
        "pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "Ka5Gb4AgCvHL",
        "outputId": "2bf34ee2-e0e1-4bed-9fbd-5d02ad5c9712"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect',\n",
              "                 CountVectorizer(analyzer='char', binary=True,\n",
              "                                 max_features=100)),\n",
              "                ('adjust_datatype',\n",
              "                 FunctionTransformer(func=<function type_adjust at 0x7d489764d090>)),\n",
              "                ('clf',\n",
              "                 <class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
              "  module=<class '__main__.ClassifierModule_grid'>,\n",
              "))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
              "                 CountVectorizer(analyzer=&#x27;char&#x27;, binary=True,\n",
              "                                 max_features=100)),\n",
              "                (&#x27;adjust_datatype&#x27;,\n",
              "                 FunctionTransformer(func=&lt;function type_adjust at 0x7d489764d090&gt;)),\n",
              "                (&#x27;clf&#x27;,\n",
              "                 &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=&lt;class &#x27;__main__.ClassifierModule_grid&#x27;&gt;,\n",
              "))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
              "                 CountVectorizer(analyzer=&#x27;char&#x27;, binary=True,\n",
              "                                 max_features=100)),\n",
              "                (&#x27;adjust_datatype&#x27;,\n",
              "                 FunctionTransformer(func=&lt;function type_adjust at 0x7d489764d090&gt;)),\n",
              "                (&#x27;clf&#x27;,\n",
              "                 &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=&lt;class &#x27;__main__.ClassifierModule_grid&#x27;&gt;,\n",
              "))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer=&#x27;char&#x27;, binary=True, max_features=100)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function type_adjust at 0x7d489764d090&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=&lt;class &#x27;__main__.ClassifierModule_grid&#x27;&gt;,\n",
              ")</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For some parameters explored in former tunation, we set fixed value to them in order to decrease the time and resource GridSearchCV needs."
      ],
      "metadata": {
        "id": "xLv6sroNCOy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters grid\n",
        "para_grid = {\n",
        "    # 'vect__max_df': [0.2, 0.4, 0.6],\n",
        "    # 'vect__ngram_range': [(1, 1), (1, 2), (2, 2), (1, 4)],\n",
        "    'vect__ngram_range': [(1, 1), (2, 2)],  # vary n-gram range\n",
        "    'clf__module__nonlin': [F.relu, F.tanh], # activation function\n",
        "    'clf__module__num_units': [300],  # hidden layer size\n",
        "    'clf__optimizer': [optim.SGD, optim.Adam],  # solvers\n",
        "    'clf__lr': [0.1, 0.01],  # learning rate\n",
        "    'clf__callbacks__EarlyStopping__patience': [5], # early stopping\n",
        "}"
      ],
      "metadata": {
        "id": "qYc1wD8f2XVI"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    para_grid,\n",
        "    verbose=1,\n",
        "    cv=3,\n",
        "    scoring='accuracy',\n",
        ")"
      ],
      "metadata": {
        "id": "KCUxjJpp3FnT"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use grid search on unvectorized training set\n",
        "grid_search.fit(X_train, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YAUoFvWH3tqz",
        "outputId": "a3a313af-9de3-4a7a-a473-6b5ef54b232c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.1187\u001b[0m       \u001b[32m0.3086\u001b[0m        \u001b[35m2.8608\u001b[0m  1.2760\n",
            "      2        \u001b[36m2.4636\u001b[0m       \u001b[32m0.4369\u001b[0m        \u001b[35m2.0840\u001b[0m  1.2802\n",
            "      3        \u001b[36m1.8189\u001b[0m       \u001b[32m0.5537\u001b[0m        \u001b[35m1.5671\u001b[0m  1.2781\n",
            "      4        \u001b[36m1.4111\u001b[0m       \u001b[32m0.6056\u001b[0m        \u001b[35m1.2606\u001b[0m  1.2609\n",
            "      5        \u001b[36m1.1744\u001b[0m       \u001b[32m0.6255\u001b[0m        \u001b[35m1.0918\u001b[0m  1.2910\n",
            "      6        \u001b[36m1.0402\u001b[0m       \u001b[32m0.6478\u001b[0m        \u001b[35m0.9932\u001b[0m  1.5814\n",
            "      7        \u001b[36m0.9584\u001b[0m       \u001b[32m0.6651\u001b[0m        \u001b[35m0.9309\u001b[0m  1.8286\n",
            "      8        \u001b[36m0.9038\u001b[0m       \u001b[32m0.6716\u001b[0m        \u001b[35m0.8887\u001b[0m  2.2498\n",
            "      9        \u001b[36m0.8655\u001b[0m       \u001b[32m0.6813\u001b[0m        \u001b[35m0.8592\u001b[0m  1.4698\n",
            "     10        \u001b[36m0.8378\u001b[0m       \u001b[32m0.6889\u001b[0m        \u001b[35m0.8388\u001b[0m  1.2895\n",
            "     11        \u001b[36m0.8170\u001b[0m       \u001b[32m0.6986\u001b[0m        \u001b[35m0.8238\u001b[0m  1.2652\n",
            "     12        \u001b[36m0.8007\u001b[0m       \u001b[32m0.7033\u001b[0m        \u001b[35m0.8123\u001b[0m  1.2857\n",
            "     13        \u001b[36m0.7874\u001b[0m       \u001b[32m0.7066\u001b[0m        \u001b[35m0.8034\u001b[0m  1.2588\n",
            "     14        \u001b[36m0.7763\u001b[0m       \u001b[32m0.7084\u001b[0m        \u001b[35m0.7958\u001b[0m  1.5445\n",
            "     15        \u001b[36m0.7667\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m0.7895\u001b[0m  1.9530\n",
            "     16        \u001b[36m0.7582\u001b[0m       0.7116        \u001b[35m0.7837\u001b[0m  1.3061\n",
            "     17        \u001b[36m0.7506\u001b[0m       0.7112        \u001b[35m0.7793\u001b[0m  1.2858\n",
            "     18        \u001b[36m0.7437\u001b[0m       \u001b[32m0.7134\u001b[0m        \u001b[35m0.7746\u001b[0m  1.2726\n",
            "     19        \u001b[36m0.7374\u001b[0m       \u001b[32m0.7156\u001b[0m        \u001b[35m0.7707\u001b[0m  1.2989\n",
            "     20        \u001b[36m0.7316\u001b[0m       \u001b[32m0.7188\u001b[0m        \u001b[35m0.7668\u001b[0m  1.2637\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.0744\u001b[0m       \u001b[32m0.3205\u001b[0m        \u001b[35m2.8033\u001b[0m  1.4276\n",
            "      2        \u001b[36m2.3778\u001b[0m       \u001b[32m0.4726\u001b[0m        \u001b[35m1.9692\u001b[0m  2.0353\n",
            "      3        \u001b[36m1.6793\u001b[0m       \u001b[32m0.5743\u001b[0m        \u001b[35m1.4662\u001b[0m  1.2700\n",
            "      4        \u001b[36m1.3157\u001b[0m       \u001b[32m0.6136\u001b[0m        \u001b[35m1.2185\u001b[0m  1.2824\n",
            "      5        \u001b[36m1.1251\u001b[0m       \u001b[32m0.6438\u001b[0m        \u001b[35m1.0727\u001b[0m  1.2701\n",
            "      6        \u001b[36m1.0097\u001b[0m       \u001b[32m0.6514\u001b[0m        \u001b[35m0.9864\u001b[0m  1.2665\n",
            "      7        \u001b[36m0.9402\u001b[0m       \u001b[32m0.6629\u001b[0m        \u001b[35m0.9333\u001b[0m  1.2485\n",
            "      8        \u001b[36m0.8956\u001b[0m       \u001b[32m0.6763\u001b[0m        \u001b[35m0.8979\u001b[0m  1.2656\n",
            "      9        \u001b[36m0.8637\u001b[0m       \u001b[32m0.6857\u001b[0m        \u001b[35m0.8734\u001b[0m  1.2531\n",
            "     10        \u001b[36m0.8389\u001b[0m       \u001b[32m0.6911\u001b[0m        \u001b[35m0.8540\u001b[0m  1.4092\n",
            "     11        \u001b[36m0.8187\u001b[0m       \u001b[32m0.6943\u001b[0m        \u001b[35m0.8390\u001b[0m  2.0781\n",
            "     12        \u001b[36m0.8022\u001b[0m       \u001b[32m0.6954\u001b[0m        \u001b[35m0.8272\u001b[0m  2.0086\n",
            "     13        \u001b[36m0.7885\u001b[0m       \u001b[32m0.6968\u001b[0m        \u001b[35m0.8185\u001b[0m  1.2455\n",
            "     14        \u001b[36m0.7771\u001b[0m       \u001b[32m0.6983\u001b[0m        \u001b[35m0.8119\u001b[0m  1.2870\n",
            "     15        \u001b[36m0.7676\u001b[0m       \u001b[32m0.7004\u001b[0m        \u001b[35m0.8065\u001b[0m  1.2795\n",
            "     16        \u001b[36m0.7595\u001b[0m       \u001b[32m0.7015\u001b[0m        \u001b[35m0.8021\u001b[0m  1.3296\n",
            "     17        \u001b[36m0.7524\u001b[0m       \u001b[32m0.7051\u001b[0m        \u001b[35m0.7984\u001b[0m  1.2417\n",
            "     18        \u001b[36m0.7460\u001b[0m       0.7051        \u001b[35m0.7954\u001b[0m  1.2489\n",
            "     19        \u001b[36m0.7402\u001b[0m       \u001b[32m0.7058\u001b[0m        \u001b[35m0.7926\u001b[0m  1.6570\n",
            "     20        \u001b[36m0.7349\u001b[0m       \u001b[32m0.7062\u001b[0m        \u001b[35m0.7903\u001b[0m  1.7847\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.1061\u001b[0m       \u001b[32m0.0721\u001b[0m        \u001b[35m2.9431\u001b[0m  1.2344\n",
            "      2        \u001b[36m2.5074\u001b[0m       \u001b[32m0.1820\u001b[0m        \u001b[35m2.5585\u001b[0m  1.2534\n",
            "      3        \u001b[36m1.7941\u001b[0m       \u001b[32m0.2632\u001b[0m        \u001b[35m2.1801\u001b[0m  1.2792\n",
            "      4        \u001b[36m1.3686\u001b[0m       \u001b[32m0.3922\u001b[0m        \u001b[35m1.7925\u001b[0m  1.2586\n",
            "      5        \u001b[36m1.1495\u001b[0m       \u001b[32m0.4463\u001b[0m        \u001b[35m1.5806\u001b[0m  1.2719\n",
            "      6        \u001b[36m1.0281\u001b[0m       \u001b[32m0.4737\u001b[0m        \u001b[35m1.4676\u001b[0m  1.5600\n",
            "      7        \u001b[36m0.9543\u001b[0m       \u001b[32m0.5076\u001b[0m        \u001b[35m1.3899\u001b[0m  1.8387\n",
            "      8        \u001b[36m0.9044\u001b[0m       \u001b[32m0.5368\u001b[0m        \u001b[35m1.3356\u001b[0m  1.2828\n",
            "      9        \u001b[36m0.8680\u001b[0m       \u001b[32m0.5497\u001b[0m        \u001b[35m1.2911\u001b[0m  1.2991\n",
            "     10        \u001b[36m0.8406\u001b[0m       \u001b[32m0.5620\u001b[0m        \u001b[35m1.2538\u001b[0m  1.2588\n",
            "     11        \u001b[36m0.8195\u001b[0m       \u001b[32m0.5667\u001b[0m        \u001b[35m1.2246\u001b[0m  1.2417\n",
            "     12        \u001b[36m0.8029\u001b[0m       \u001b[32m0.5743\u001b[0m        \u001b[35m1.2035\u001b[0m  1.6149\n",
            "     13        \u001b[36m0.7896\u001b[0m       \u001b[32m0.5811\u001b[0m        \u001b[35m1.1828\u001b[0m  1.8494\n",
            "     14        \u001b[36m0.7783\u001b[0m       \u001b[32m0.5847\u001b[0m        \u001b[35m1.1631\u001b[0m  1.3489\n",
            "     15        \u001b[36m0.7685\u001b[0m       \u001b[32m0.5887\u001b[0m        \u001b[35m1.1480\u001b[0m  2.0652\n",
            "     16        \u001b[36m0.7600\u001b[0m       \u001b[32m0.5919\u001b[0m        \u001b[35m1.1365\u001b[0m  1.3121\n",
            "     17        \u001b[36m0.7528\u001b[0m       \u001b[32m0.5988\u001b[0m        \u001b[35m1.1227\u001b[0m  1.2609\n",
            "     18        \u001b[36m0.7462\u001b[0m       \u001b[32m0.6027\u001b[0m        \u001b[35m1.1094\u001b[0m  1.2410\n",
            "     19        \u001b[36m0.7401\u001b[0m       \u001b[32m0.6056\u001b[0m        \u001b[35m1.1012\u001b[0m  1.2632\n",
            "     20        \u001b[36m0.7346\u001b[0m       \u001b[32m0.6081\u001b[0m        \u001b[35m1.0870\u001b[0m  1.2935\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.0169\u001b[0m       \u001b[32m0.2361\u001b[0m        \u001b[35m2.7594\u001b[0m  1.8160\n",
            "      2        \u001b[36m2.4669\u001b[0m       \u001b[32m0.4625\u001b[0m        \u001b[35m2.1315\u001b[0m  1.2971\n",
            "      3        \u001b[36m1.8726\u001b[0m       \u001b[32m0.5224\u001b[0m        \u001b[35m1.6215\u001b[0m  1.2845\n",
            "      4        \u001b[36m1.4979\u001b[0m       \u001b[32m0.5735\u001b[0m        \u001b[35m1.3698\u001b[0m  1.2891\n",
            "      5        \u001b[36m1.2996\u001b[0m       \u001b[32m0.5890\u001b[0m        \u001b[35m1.2509\u001b[0m  1.2896\n",
            "      6        \u001b[36m1.1984\u001b[0m       \u001b[32m0.5919\u001b[0m        \u001b[35m1.1917\u001b[0m  1.3213\n",
            "      7        \u001b[36m1.1382\u001b[0m       \u001b[32m0.6045\u001b[0m        \u001b[35m1.1572\u001b[0m  1.3045\n",
            "      8        \u001b[36m1.0960\u001b[0m       \u001b[32m0.6060\u001b[0m        \u001b[35m1.1341\u001b[0m  1.2967\n",
            "      9        \u001b[36m1.0641\u001b[0m       \u001b[32m0.6118\u001b[0m        \u001b[35m1.1161\u001b[0m  1.7343\n",
            "     10        \u001b[36m1.0384\u001b[0m       \u001b[32m0.6132\u001b[0m        \u001b[35m1.1026\u001b[0m  1.7021\n",
            "     11        \u001b[36m1.0175\u001b[0m       0.6132        \u001b[35m1.0933\u001b[0m  1.3061\n",
            "     12        \u001b[36m1.0005\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m1.0849\u001b[0m  1.2718\n",
            "     13        \u001b[36m0.9860\u001b[0m       0.6168        \u001b[35m1.0795\u001b[0m  1.2951\n",
            "     14        \u001b[36m0.9739\u001b[0m       \u001b[32m0.6175\u001b[0m        \u001b[35m1.0749\u001b[0m  1.3497\n",
            "     15        \u001b[36m0.9635\u001b[0m       \u001b[32m0.6193\u001b[0m        \u001b[35m1.0706\u001b[0m  1.2951\n",
            "     16        \u001b[36m0.9543\u001b[0m       \u001b[32m0.6208\u001b[0m        \u001b[35m1.0671\u001b[0m  1.2663\n",
            "     17        \u001b[36m0.9461\u001b[0m       0.6208        \u001b[35m1.0643\u001b[0m  1.3095\n",
            "     18        \u001b[36m0.9387\u001b[0m       \u001b[32m0.6215\u001b[0m        \u001b[35m1.0622\u001b[0m  1.8356\n",
            "     19        \u001b[36m0.9318\u001b[0m       \u001b[32m0.6222\u001b[0m        \u001b[35m1.0602\u001b[0m  1.6224\n",
            "     20        \u001b[36m0.9254\u001b[0m       0.6218        \u001b[35m1.0578\u001b[0m  1.2745\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.0075\u001b[0m       \u001b[32m0.2177\u001b[0m        \u001b[35m2.7718\u001b[0m  1.2431\n",
            "      2        \u001b[36m2.4943\u001b[0m       \u001b[32m0.3976\u001b[0m        \u001b[35m2.1984\u001b[0m  1.2682\n",
            "      3        \u001b[36m1.9440\u001b[0m       \u001b[32m0.4715\u001b[0m        \u001b[35m1.7155\u001b[0m  1.7171\n",
            "      4        \u001b[36m1.5951\u001b[0m       \u001b[32m0.5714\u001b[0m        \u001b[35m1.4560\u001b[0m  1.8352\n",
            "      5        \u001b[36m1.3770\u001b[0m       \u001b[32m0.5912\u001b[0m        \u001b[35m1.2915\u001b[0m  1.2555\n",
            "      6        \u001b[36m1.2395\u001b[0m       \u001b[32m0.6056\u001b[0m        \u001b[35m1.1995\u001b[0m  1.2477\n",
            "      7        \u001b[36m1.1603\u001b[0m       \u001b[32m0.6121\u001b[0m        \u001b[35m1.1459\u001b[0m  1.2777\n",
            "      8        \u001b[36m1.1099\u001b[0m       \u001b[32m0.6182\u001b[0m        \u001b[35m1.1134\u001b[0m  1.2632\n",
            "      9        \u001b[36m1.0749\u001b[0m       \u001b[32m0.6211\u001b[0m        \u001b[35m1.0914\u001b[0m  1.2603\n",
            "     10        \u001b[36m1.0481\u001b[0m       \u001b[32m0.6247\u001b[0m        \u001b[35m1.0753\u001b[0m  1.3410\n",
            "     11        \u001b[36m1.0268\u001b[0m       \u001b[32m0.6276\u001b[0m        \u001b[35m1.0636\u001b[0m  1.2909\n",
            "     12        \u001b[36m1.0094\u001b[0m       \u001b[32m0.6319\u001b[0m        \u001b[35m1.0538\u001b[0m  1.7099\n",
            "     13        \u001b[36m0.9947\u001b[0m       \u001b[32m0.6334\u001b[0m        \u001b[35m1.0473\u001b[0m  1.7363\n",
            "     14        \u001b[36m0.9824\u001b[0m       \u001b[32m0.6355\u001b[0m        \u001b[35m1.0422\u001b[0m  1.2518\n",
            "     15        \u001b[36m0.9715\u001b[0m       \u001b[32m0.6366\u001b[0m        \u001b[35m1.0382\u001b[0m  1.2720\n",
            "     16        \u001b[36m0.9619\u001b[0m       \u001b[32m0.6370\u001b[0m        \u001b[35m1.0346\u001b[0m  1.2829\n",
            "     17        \u001b[36m0.9531\u001b[0m       \u001b[32m0.6381\u001b[0m        \u001b[35m1.0320\u001b[0m  1.2431\n",
            "     18        \u001b[36m0.9452\u001b[0m       \u001b[32m0.6388\u001b[0m        \u001b[35m1.0297\u001b[0m  1.2724\n",
            "     19        \u001b[36m0.9379\u001b[0m       \u001b[32m0.6399\u001b[0m        \u001b[35m1.0283\u001b[0m  1.2683\n",
            "     20        \u001b[36m0.9310\u001b[0m       \u001b[32m0.6406\u001b[0m        \u001b[35m1.0268\u001b[0m  1.2702\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.9916\u001b[0m       \u001b[32m0.0984\u001b[0m        \u001b[35m3.1022\u001b[0m  1.2433\n",
            "      2        \u001b[36m2.4367\u001b[0m       \u001b[32m0.2001\u001b[0m        \u001b[35m3.0150\u001b[0m  1.2984\n",
            "      3        \u001b[36m1.8733\u001b[0m       \u001b[32m0.2433\u001b[0m        \u001b[35m2.4625\u001b[0m  1.2574\n",
            "      4        \u001b[36m1.5453\u001b[0m       \u001b[32m0.3699\u001b[0m        \u001b[35m1.8565\u001b[0m  1.2531\n",
            "      5        \u001b[36m1.3477\u001b[0m       \u001b[32m0.4448\u001b[0m        \u001b[35m1.6155\u001b[0m  1.2653\n",
            "      6        \u001b[36m1.2348\u001b[0m       \u001b[32m0.4755\u001b[0m        \u001b[35m1.5204\u001b[0m  1.4813\n",
            "      7        \u001b[36m1.1737\u001b[0m       \u001b[32m0.4960\u001b[0m        \u001b[35m1.4699\u001b[0m  1.9607\n",
            "      8        \u001b[36m1.1349\u001b[0m       \u001b[32m0.5068\u001b[0m        \u001b[35m1.4335\u001b[0m  1.3058\n",
            "      9        \u001b[36m1.1062\u001b[0m       \u001b[32m0.5213\u001b[0m        \u001b[35m1.3979\u001b[0m  1.2882\n",
            "     10        \u001b[36m1.0830\u001b[0m       \u001b[32m0.5321\u001b[0m        \u001b[35m1.3743\u001b[0m  1.3577\n",
            "     11        \u001b[36m1.0634\u001b[0m       \u001b[32m0.5389\u001b[0m        \u001b[35m1.3492\u001b[0m  1.2901\n",
            "     12        \u001b[36m1.0463\u001b[0m       \u001b[32m0.5443\u001b[0m        \u001b[35m1.3294\u001b[0m  1.3017\n",
            "     13        \u001b[36m1.0314\u001b[0m       \u001b[32m0.5501\u001b[0m        \u001b[35m1.3133\u001b[0m  1.2911\n",
            "     14        \u001b[36m1.0183\u001b[0m       \u001b[32m0.5530\u001b[0m        \u001b[35m1.3007\u001b[0m  1.2892\n",
            "     15        \u001b[36m1.0067\u001b[0m       \u001b[32m0.5562\u001b[0m        \u001b[35m1.2893\u001b[0m  1.6310\n",
            "     16        \u001b[36m0.9962\u001b[0m       \u001b[32m0.5591\u001b[0m        \u001b[35m1.2807\u001b[0m  1.8448\n",
            "     17        \u001b[36m0.9869\u001b[0m       \u001b[32m0.5613\u001b[0m        \u001b[35m1.2712\u001b[0m  1.3028\n",
            "     18        \u001b[36m0.9784\u001b[0m       \u001b[32m0.5638\u001b[0m        \u001b[35m1.2642\u001b[0m  1.2689\n",
            "     19        \u001b[36m0.9704\u001b[0m       \u001b[32m0.5652\u001b[0m        \u001b[35m1.2578\u001b[0m  1.2705\n",
            "     20        \u001b[36m0.9632\u001b[0m       \u001b[32m0.5678\u001b[0m        \u001b[35m1.2519\u001b[0m  1.2819\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.9692\u001b[0m       \u001b[32m0.3738\u001b[0m        \u001b[35m1.7149\u001b[0m  1.3235\n",
            "      2        \u001b[36m1.6200\u001b[0m       \u001b[32m0.4167\u001b[0m        \u001b[35m1.6216\u001b[0m  2.0277\n",
            "      3        \u001b[36m1.4334\u001b[0m       \u001b[32m0.4625\u001b[0m        \u001b[35m1.4844\u001b[0m  1.5953\n",
            "      4        \u001b[36m1.3699\u001b[0m       \u001b[32m0.5043\u001b[0m        \u001b[35m1.4065\u001b[0m  1.3235\n",
            "      5        \u001b[36m1.3484\u001b[0m       0.4870        \u001b[35m1.3760\u001b[0m  1.3569\n",
            "      6        1.3884       0.4978        1.4082  1.3706\n",
            "      7        \u001b[36m1.2862\u001b[0m       \u001b[32m0.5375\u001b[0m        \u001b[35m1.2621\u001b[0m  1.3637\n",
            "      8        \u001b[36m1.2256\u001b[0m       0.5234        1.3193  1.5341\n",
            "      9        1.2478       \u001b[32m0.5501\u001b[0m        \u001b[35m1.2487\u001b[0m  2.0247\n",
            "     10        \u001b[36m1.1993\u001b[0m       0.5317        1.2709  2.2248\n",
            "     11        1.2430       0.5458        1.3396  1.5777\n",
            "     12        1.2567       0.4910        1.3675  1.5045\n",
            "     13        1.2389       \u001b[32m0.5519\u001b[0m        \u001b[35m1.2165\u001b[0m  1.4145\n",
            "     14        \u001b[36m1.1893\u001b[0m       0.5447        1.2608  1.4945\n",
            "     15        1.2209       \u001b[32m0.5570\u001b[0m        \u001b[35m1.2081\u001b[0m  1.4689\n",
            "     16        1.2091       \u001b[32m0.5671\u001b[0m        1.2251  1.4742\n",
            "     17        1.2245       0.5638        1.2165  1.4689\n",
            "     18        1.2243       0.5267        1.2927  2.3798\n",
            "     19        \u001b[36m1.1811\u001b[0m       \u001b[32m0.5869\u001b[0m        1.2083  1.5119\n",
            "     20        1.1961       0.5771        \u001b[35m1.2064\u001b[0m  1.4397\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.3250\u001b[0m       \u001b[32m0.5429\u001b[0m        \u001b[35m1.2748\u001b[0m  1.3108\n",
            "      2        \u001b[36m1.1791\u001b[0m       \u001b[32m0.5948\u001b[0m        \u001b[35m1.1441\u001b[0m  1.3110\n",
            "      3        \u001b[36m1.0908\u001b[0m       \u001b[32m0.6150\u001b[0m        \u001b[35m1.0574\u001b[0m  1.3437\n",
            "      4        1.1002       0.5804        1.1227  1.7424\n",
            "      5        1.0929       0.5883        1.1417  1.8913\n",
            "      6        1.1001       0.6150        1.0695  1.3181\n",
            "      7        1.1467       0.5934        1.1457  1.4251\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.8244\u001b[0m       \u001b[32m0.3792\u001b[0m        \u001b[35m1.7524\u001b[0m  1.2954\n",
            "      2        \u001b[36m1.5206\u001b[0m       \u001b[32m0.4694\u001b[0m        \u001b[35m1.6861\u001b[0m  1.3367\n",
            "      3        \u001b[36m1.3641\u001b[0m       \u001b[32m0.5494\u001b[0m        \u001b[35m1.2022\u001b[0m  1.9408\n",
            "      4        \u001b[36m1.2880\u001b[0m       0.5166        1.4994  1.6289\n",
            "      5        \u001b[36m1.2879\u001b[0m       0.5256        1.3507  1.3333\n",
            "      6        \u001b[36m1.2495\u001b[0m       0.5195        1.5260  1.2937\n",
            "      7        1.3844       0.5040        1.4552  1.3189\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.2510\u001b[0m       \u001b[32m0.3309\u001b[0m        \u001b[35m1.8267\u001b[0m  1.9884\n",
            "      2        \u001b[36m1.7837\u001b[0m       \u001b[32m0.3576\u001b[0m        \u001b[35m1.7283\u001b[0m  1.3404\n",
            "      3        \u001b[36m1.7094\u001b[0m       \u001b[32m0.3663\u001b[0m        \u001b[35m1.7132\u001b[0m  1.3365\n",
            "      4        \u001b[36m1.6819\u001b[0m       \u001b[32m0.3846\u001b[0m        \u001b[35m1.7074\u001b[0m  1.3443\n",
            "      5        \u001b[36m1.6750\u001b[0m       \u001b[32m0.3965\u001b[0m        \u001b[35m1.6686\u001b[0m  1.3394\n",
            "      6        \u001b[36m1.6440\u001b[0m       0.3951        1.7227  1.3373\n",
            "      7        \u001b[36m1.6410\u001b[0m       0.3875        1.6994  1.3507\n",
            "      8        \u001b[36m1.6136\u001b[0m       0.3839        \u001b[35m1.6584\u001b[0m  1.4081\n",
            "      9        1.6238       0.3536        1.8279  2.2147\n",
            "     10        1.6548       0.3843        1.7443  1.5994\n",
            "     11        1.6463       0.3864        1.7321  1.4542\n",
            "     12        1.6168       0.3922        1.7160  1.4729\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.7943\u001b[0m       \u001b[32m0.2938\u001b[0m        \u001b[35m2.0041\u001b[0m  1.8956\n",
            "      2        \u001b[36m1.9247\u001b[0m       \u001b[32m0.3515\u001b[0m        \u001b[35m1.8167\u001b[0m  1.3404\n",
            "      3        \u001b[36m1.8076\u001b[0m       \u001b[32m0.3609\u001b[0m        1.8333  1.3444\n",
            "      4        \u001b[36m1.6954\u001b[0m       \u001b[32m0.4074\u001b[0m        \u001b[35m1.6790\u001b[0m  1.3262\n",
            "      5        \u001b[36m1.6686\u001b[0m       \u001b[32m0.4131\u001b[0m        1.6954  1.3002\n",
            "      6        \u001b[36m1.6403\u001b[0m       \u001b[32m0.4243\u001b[0m        \u001b[35m1.6722\u001b[0m  1.3467\n",
            "      7        \u001b[36m1.6300\u001b[0m       \u001b[32m0.4376\u001b[0m        1.7036  1.3380\n",
            "      8        \u001b[36m1.6025\u001b[0m       \u001b[32m0.4492\u001b[0m        \u001b[35m1.6493\u001b[0m  1.3541\n",
            "      9        1.6053       0.4441        1.6498  2.0792\n",
            "     10        \u001b[36m1.6017\u001b[0m       \u001b[32m0.4535\u001b[0m        1.6613  1.7498\n",
            "     11        1.6237       0.4268        1.6679  1.4517\n",
            "     12        \u001b[36m1.5809\u001b[0m       0.4459        1.6519  1.5118\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.2523\u001b[0m       \u001b[32m0.2873\u001b[0m        \u001b[35m2.1026\u001b[0m  1.8983\n",
            "      2        \u001b[36m1.9779\u001b[0m       \u001b[32m0.3165\u001b[0m        \u001b[35m2.0308\u001b[0m  1.3131\n",
            "      3        \u001b[36m1.8893\u001b[0m       \u001b[32m0.3288\u001b[0m        \u001b[35m1.9187\u001b[0m  1.3530\n",
            "      4        \u001b[36m1.8208\u001b[0m       \u001b[32m0.3374\u001b[0m        \u001b[35m1.8514\u001b[0m  1.3388\n",
            "      5        1.8584       0.3136        2.0247  1.3342\n",
            "      6        \u001b[36m1.8138\u001b[0m       \u001b[32m0.3540\u001b[0m        \u001b[35m1.8287\u001b[0m  1.3551\n",
            "      7        \u001b[36m1.7682\u001b[0m       0.3349        1.8529  1.3229\n",
            "      8        \u001b[36m1.7649\u001b[0m       0.3472        \u001b[35m1.8128\u001b[0m  1.3454\n",
            "      9        \u001b[36m1.7389\u001b[0m       \u001b[32m0.3583\u001b[0m        \u001b[35m1.7459\u001b[0m  2.1702\n",
            "     10        \u001b[36m1.7138\u001b[0m       0.3551        1.7858  1.6664\n",
            "     11        1.7388       0.3547        1.7933  1.4765\n",
            "     12        1.7517       \u001b[32m0.3630\u001b[0m        1.8656  1.4432\n",
            "     13        1.7792       0.3421        1.8831  1.4291\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.9541\u001b[0m       \u001b[32m0.3612\u001b[0m        \u001b[35m2.5483\u001b[0m  2.0740\n",
            "      2        \u001b[36m2.1583\u001b[0m       \u001b[32m0.5443\u001b[0m        \u001b[35m1.7767\u001b[0m  1.3346\n",
            "      3        \u001b[36m1.5338\u001b[0m       \u001b[32m0.6186\u001b[0m        \u001b[35m1.3271\u001b[0m  1.2979\n",
            "      4        \u001b[36m1.2092\u001b[0m       \u001b[32m0.6460\u001b[0m        \u001b[35m1.1040\u001b[0m  1.2750\n",
            "      5        \u001b[36m1.0365\u001b[0m       \u001b[32m0.6615\u001b[0m        \u001b[35m0.9810\u001b[0m  1.2916\n",
            "      6        \u001b[36m0.9396\u001b[0m       \u001b[32m0.6788\u001b[0m        \u001b[35m0.9131\u001b[0m  1.2841\n",
            "      7        \u001b[36m0.8815\u001b[0m       \u001b[32m0.6896\u001b[0m        \u001b[35m0.8717\u001b[0m  1.2981\n",
            "      8        \u001b[36m0.8427\u001b[0m       \u001b[32m0.6950\u001b[0m        \u001b[35m0.8442\u001b[0m  1.2845\n",
            "      9        \u001b[36m0.8150\u001b[0m       \u001b[32m0.6990\u001b[0m        \u001b[35m0.8251\u001b[0m  1.5922\n",
            "     10        \u001b[36m0.7946\u001b[0m       \u001b[32m0.7033\u001b[0m        \u001b[35m0.8115\u001b[0m  1.9360\n",
            "     11        \u001b[36m0.7791\u001b[0m       \u001b[32m0.7066\u001b[0m        \u001b[35m0.8012\u001b[0m  1.2912\n",
            "     12        \u001b[36m0.7668\u001b[0m       \u001b[32m0.7076\u001b[0m        \u001b[35m0.7934\u001b[0m  1.3069\n",
            "     13        \u001b[36m0.7567\u001b[0m       \u001b[32m0.7102\u001b[0m        \u001b[35m0.7870\u001b[0m  1.3065\n",
            "     14        \u001b[36m0.7482\u001b[0m       \u001b[32m0.7109\u001b[0m        \u001b[35m0.7815\u001b[0m  1.3053\n",
            "     15        \u001b[36m0.7409\u001b[0m       \u001b[32m0.7152\u001b[0m        \u001b[35m0.7768\u001b[0m  1.3705\n",
            "     16        \u001b[36m0.7344\u001b[0m       \u001b[32m0.7156\u001b[0m        \u001b[35m0.7732\u001b[0m  1.3423\n",
            "     17        \u001b[36m0.7287\u001b[0m       \u001b[32m0.7159\u001b[0m        \u001b[35m0.7698\u001b[0m  1.2956\n",
            "     18        \u001b[36m0.7236\u001b[0m       \u001b[32m0.7177\u001b[0m        \u001b[35m0.7666\u001b[0m  1.7424\n",
            "     19        \u001b[36m0.7189\u001b[0m       \u001b[32m0.7221\u001b[0m        \u001b[35m0.7640\u001b[0m  1.7685\n",
            "     20        \u001b[36m0.7146\u001b[0m       \u001b[32m0.7231\u001b[0m        \u001b[35m0.7615\u001b[0m  1.3160\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.9812\u001b[0m       \u001b[32m0.3356\u001b[0m        \u001b[35m2.5942\u001b[0m  1.3071\n",
            "      2        \u001b[36m2.2038\u001b[0m       \u001b[32m0.4993\u001b[0m        \u001b[35m1.8762\u001b[0m  1.2877\n",
            "      3        \u001b[36m1.6328\u001b[0m       \u001b[32m0.5944\u001b[0m        \u001b[35m1.4437\u001b[0m  1.2619\n",
            "      4        \u001b[36m1.2860\u001b[0m       \u001b[32m0.6474\u001b[0m        \u001b[35m1.1892\u001b[0m  1.4817\n",
            "      5        \u001b[36m1.0850\u001b[0m       \u001b[32m0.6647\u001b[0m        \u001b[35m1.0388\u001b[0m  1.9975\n",
            "      6        \u001b[36m0.9688\u001b[0m       \u001b[32m0.6756\u001b[0m        \u001b[35m0.9527\u001b[0m  1.2733\n",
            "      7        \u001b[36m0.9021\u001b[0m       \u001b[32m0.6857\u001b[0m        \u001b[35m0.9021\u001b[0m  1.3175\n",
            "      8        \u001b[36m0.8605\u001b[0m       \u001b[32m0.6936\u001b[0m        \u001b[35m0.8700\u001b[0m  1.3164\n",
            "      9        \u001b[36m0.8321\u001b[0m       0.6936        \u001b[35m0.8484\u001b[0m  1.3019\n",
            "     10        \u001b[36m0.8115\u001b[0m       \u001b[32m0.6983\u001b[0m        \u001b[35m0.8331\u001b[0m  1.2670\n",
            "     11        \u001b[36m0.7955\u001b[0m       \u001b[32m0.6986\u001b[0m        \u001b[35m0.8220\u001b[0m  1.2746\n",
            "     12        \u001b[36m0.7827\u001b[0m       \u001b[32m0.7015\u001b[0m        \u001b[35m0.8134\u001b[0m  1.2909\n",
            "     13        \u001b[36m0.7719\u001b[0m       \u001b[32m0.7037\u001b[0m        \u001b[35m0.8069\u001b[0m  1.5290\n",
            "     14        \u001b[36m0.7628\u001b[0m       \u001b[32m0.7069\u001b[0m        \u001b[35m0.8018\u001b[0m  1.9139\n",
            "     15        \u001b[36m0.7549\u001b[0m       \u001b[32m0.7076\u001b[0m        \u001b[35m0.7977\u001b[0m  1.3031\n",
            "     16        \u001b[36m0.7481\u001b[0m       0.7073        \u001b[35m0.7943\u001b[0m  1.2795\n",
            "     17        \u001b[36m0.7422\u001b[0m       0.7076        \u001b[35m0.7913\u001b[0m  1.2706\n",
            "     18        \u001b[36m0.7368\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m0.7885\u001b[0m  1.3166\n",
            "     19        \u001b[36m0.7320\u001b[0m       \u001b[32m0.7152\u001b[0m        \u001b[35m0.7863\u001b[0m  1.2708\n",
            "     20        \u001b[36m0.7275\u001b[0m       \u001b[32m0.7163\u001b[0m        \u001b[35m0.7842\u001b[0m  1.3054\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.9667\u001b[0m       \u001b[32m0.1626\u001b[0m        \u001b[35m2.6557\u001b[0m  1.8597\n",
            "      2        \u001b[36m2.1271\u001b[0m       \u001b[32m0.2588\u001b[0m        \u001b[35m2.0671\u001b[0m  1.2763\n",
            "      3        \u001b[36m1.5550\u001b[0m       \u001b[32m0.4110\u001b[0m        \u001b[35m1.6038\u001b[0m  1.2623\n",
            "      4        \u001b[36m1.2458\u001b[0m       \u001b[32m0.4694\u001b[0m        \u001b[35m1.3859\u001b[0m  1.2515\n",
            "      5        \u001b[36m1.0664\u001b[0m       \u001b[32m0.5209\u001b[0m        \u001b[35m1.2625\u001b[0m  1.2647\n",
            "      6        \u001b[36m0.9616\u001b[0m       \u001b[32m0.5638\u001b[0m        \u001b[35m1.1931\u001b[0m  1.3028\n",
            "      7        \u001b[36m0.9006\u001b[0m       \u001b[32m0.5786\u001b[0m        \u001b[35m1.1498\u001b[0m  1.2671\n",
            "      8        \u001b[36m0.8614\u001b[0m       \u001b[32m0.5901\u001b[0m        \u001b[35m1.1217\u001b[0m  1.2904\n",
            "      9        \u001b[36m0.8340\u001b[0m       \u001b[32m0.5977\u001b[0m        \u001b[35m1.0994\u001b[0m  1.7021\n",
            "     10        \u001b[36m0.8139\u001b[0m       \u001b[32m0.6027\u001b[0m        \u001b[35m1.0821\u001b[0m  1.7643\n",
            "     11        \u001b[36m0.7984\u001b[0m       \u001b[32m0.6081\u001b[0m        \u001b[35m1.0676\u001b[0m  1.3126\n",
            "     12        \u001b[36m0.7863\u001b[0m       \u001b[32m0.6132\u001b[0m        \u001b[35m1.0571\u001b[0m  1.2615\n",
            "     13        \u001b[36m0.7765\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m1.0473\u001b[0m  1.2872\n",
            "     14        \u001b[36m0.7682\u001b[0m       \u001b[32m0.6208\u001b[0m        \u001b[35m1.0396\u001b[0m  2.2262\n",
            "     15        \u001b[36m0.7612\u001b[0m       \u001b[32m0.6229\u001b[0m        \u001b[35m1.0312\u001b[0m  1.5865\n",
            "     16        \u001b[36m0.7550\u001b[0m       \u001b[32m0.6258\u001b[0m        \u001b[35m1.0252\u001b[0m  1.2716\n",
            "     17        \u001b[36m0.7495\u001b[0m       \u001b[32m0.6273\u001b[0m        \u001b[35m1.0186\u001b[0m  1.7805\n",
            "     18        \u001b[36m0.7445\u001b[0m       \u001b[32m0.6298\u001b[0m        \u001b[35m1.0133\u001b[0m  1.7866\n",
            "     19        \u001b[36m0.7400\u001b[0m       \u001b[32m0.6330\u001b[0m        \u001b[35m1.0065\u001b[0m  1.2933\n",
            "     20        \u001b[36m0.7359\u001b[0m       \u001b[32m0.6355\u001b[0m        \u001b[35m1.0005\u001b[0m  1.2973\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.9779\u001b[0m       \u001b[32m0.2761\u001b[0m        \u001b[35m2.6762\u001b[0m  1.2835\n",
            "      2        \u001b[36m2.3394\u001b[0m       \u001b[32m0.4423\u001b[0m        \u001b[35m2.0077\u001b[0m  1.4418\n",
            "      3        \u001b[36m1.7529\u001b[0m       \u001b[32m0.5501\u001b[0m        \u001b[35m1.5430\u001b[0m  2.0467\n",
            "      4        \u001b[36m1.3994\u001b[0m       \u001b[32m0.5667\u001b[0m        \u001b[35m1.3133\u001b[0m  1.3131\n",
            "      5        \u001b[36m1.2358\u001b[0m       \u001b[32m0.5800\u001b[0m        \u001b[35m1.2189\u001b[0m  1.3440\n",
            "      6        \u001b[36m1.1579\u001b[0m       \u001b[32m0.5898\u001b[0m        \u001b[35m1.1728\u001b[0m  1.2732\n",
            "      7        \u001b[36m1.1110\u001b[0m       \u001b[32m0.6031\u001b[0m        \u001b[35m1.1450\u001b[0m  1.3189\n",
            "      8        \u001b[36m1.0773\u001b[0m       \u001b[32m0.6049\u001b[0m        \u001b[35m1.1251\u001b[0m  1.2693\n",
            "      9        \u001b[36m1.0505\u001b[0m       \u001b[32m0.6067\u001b[0m        \u001b[35m1.1097\u001b[0m  1.2602\n",
            "     10        \u001b[36m1.0288\u001b[0m       \u001b[32m0.6114\u001b[0m        \u001b[35m1.0980\u001b[0m  1.2735\n",
            "     11        \u001b[36m1.0108\u001b[0m       \u001b[32m0.6136\u001b[0m        \u001b[35m1.0892\u001b[0m  1.5584\n",
            "     12        \u001b[36m0.9960\u001b[0m       \u001b[32m0.6172\u001b[0m        \u001b[35m1.0825\u001b[0m  1.9688\n",
            "     13        \u001b[36m0.9834\u001b[0m       \u001b[32m0.6197\u001b[0m        \u001b[35m1.0775\u001b[0m  1.2863\n",
            "     14        \u001b[36m0.9727\u001b[0m       \u001b[32m0.6215\u001b[0m        \u001b[35m1.0732\u001b[0m  1.3131\n",
            "     15        \u001b[36m0.9634\u001b[0m       0.6208        \u001b[35m1.0698\u001b[0m  1.3508\n",
            "     16        \u001b[36m0.9552\u001b[0m       0.6211        \u001b[35m1.0671\u001b[0m  1.3160\n",
            "     17        \u001b[36m0.9479\u001b[0m       \u001b[32m0.6229\u001b[0m        \u001b[35m1.0644\u001b[0m  1.2954\n",
            "     18        \u001b[36m0.9412\u001b[0m       \u001b[32m0.6236\u001b[0m        \u001b[35m1.0625\u001b[0m  1.2782\n",
            "     19        \u001b[36m0.9351\u001b[0m       \u001b[32m0.6244\u001b[0m        \u001b[35m1.0608\u001b[0m  1.3250\n",
            "     20        \u001b[36m0.9295\u001b[0m       0.6240        \u001b[35m1.0587\u001b[0m  1.6543\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.9809\u001b[0m       \u001b[32m0.2170\u001b[0m        \u001b[35m2.6535\u001b[0m  1.2859\n",
            "      2        \u001b[36m2.3476\u001b[0m       \u001b[32m0.4355\u001b[0m        \u001b[35m2.0661\u001b[0m  1.2853\n",
            "      3        \u001b[36m1.8148\u001b[0m       \u001b[32m0.5512\u001b[0m        \u001b[35m1.5965\u001b[0m  1.2784\n",
            "      4        \u001b[36m1.4451\u001b[0m       \u001b[32m0.5771\u001b[0m        \u001b[35m1.3370\u001b[0m  1.2774\n",
            "      5        \u001b[36m1.2623\u001b[0m       \u001b[32m0.5919\u001b[0m        \u001b[35m1.2219\u001b[0m  1.6216\n",
            "      6        \u001b[36m1.1745\u001b[0m       \u001b[32m0.6035\u001b[0m        \u001b[35m1.1634\u001b[0m  1.8496\n",
            "      7        \u001b[36m1.1229\u001b[0m       \u001b[32m0.6092\u001b[0m        \u001b[35m1.1277\u001b[0m  1.2781\n",
            "      8        \u001b[36m1.0865\u001b[0m       \u001b[32m0.6211\u001b[0m        \u001b[35m1.1027\u001b[0m  1.3062\n",
            "      9        \u001b[36m1.0584\u001b[0m       \u001b[32m0.6222\u001b[0m        \u001b[35m1.0851\u001b[0m  1.2481\n",
            "     10        \u001b[36m1.0358\u001b[0m       \u001b[32m0.6291\u001b[0m        \u001b[35m1.0713\u001b[0m  1.2596\n",
            "     11        \u001b[36m1.0174\u001b[0m       \u001b[32m0.6316\u001b[0m        \u001b[35m1.0613\u001b[0m  1.2877\n",
            "     12        \u001b[36m1.0022\u001b[0m       \u001b[32m0.6319\u001b[0m        \u001b[35m1.0540\u001b[0m  1.3026\n",
            "     13        \u001b[36m0.9895\u001b[0m       \u001b[32m0.6334\u001b[0m        \u001b[35m1.0484\u001b[0m  1.3379\n",
            "     14        \u001b[36m0.9786\u001b[0m       \u001b[32m0.6384\u001b[0m        \u001b[35m1.0438\u001b[0m  1.8078\n",
            "     15        \u001b[36m0.9691\u001b[0m       \u001b[32m0.6413\u001b[0m        \u001b[35m1.0399\u001b[0m  2.6933\n",
            "     16        \u001b[36m0.9606\u001b[0m       \u001b[32m0.6420\u001b[0m        \u001b[35m1.0372\u001b[0m  1.9887\n",
            "     17        \u001b[36m0.9530\u001b[0m       \u001b[32m0.6431\u001b[0m        \u001b[35m1.0348\u001b[0m  1.2935\n",
            "     18        \u001b[36m0.9463\u001b[0m       0.6431        \u001b[35m1.0328\u001b[0m  1.2845\n",
            "     19        \u001b[36m0.9400\u001b[0m       0.6413        \u001b[35m1.0315\u001b[0m  1.2887\n",
            "     20        \u001b[36m0.9343\u001b[0m       0.6410        \u001b[35m1.0301\u001b[0m  1.2860\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m2.9756\u001b[0m       \u001b[32m0.1449\u001b[0m        \u001b[35m2.8642\u001b[0m  1.2588\n",
            "      2        \u001b[36m2.3479\u001b[0m       \u001b[32m0.2112\u001b[0m        \u001b[35m2.4375\u001b[0m  1.2883\n",
            "      3        \u001b[36m1.7973\u001b[0m       \u001b[32m0.3104\u001b[0m        \u001b[35m1.9353\u001b[0m  1.3037\n",
            "      4        \u001b[36m1.4611\u001b[0m       \u001b[32m0.4066\u001b[0m        \u001b[35m1.6042\u001b[0m  1.3608\n",
            "      5        \u001b[36m1.2882\u001b[0m       \u001b[32m0.4683\u001b[0m        \u001b[35m1.4539\u001b[0m  1.3543\n",
            "      6        \u001b[36m1.1984\u001b[0m       \u001b[32m0.5061\u001b[0m        \u001b[35m1.3803\u001b[0m  1.3080\n",
            "      7        \u001b[36m1.1438\u001b[0m       \u001b[32m0.5451\u001b[0m        \u001b[35m1.3354\u001b[0m  2.0277\n",
            "      8        \u001b[36m1.1056\u001b[0m       \u001b[32m0.5523\u001b[0m        \u001b[35m1.3054\u001b[0m  1.4338\n",
            "      9        \u001b[36m1.0763\u001b[0m       \u001b[32m0.5588\u001b[0m        \u001b[35m1.2824\u001b[0m  1.2959\n",
            "     10        \u001b[36m1.0531\u001b[0m       \u001b[32m0.5638\u001b[0m        \u001b[35m1.2660\u001b[0m  1.3159\n",
            "     11        \u001b[36m1.0347\u001b[0m       \u001b[32m0.5663\u001b[0m        \u001b[35m1.2534\u001b[0m  1.3005\n",
            "     12        \u001b[36m1.0195\u001b[0m       \u001b[32m0.5689\u001b[0m        \u001b[35m1.2435\u001b[0m  1.2878\n",
            "     13        \u001b[36m1.0068\u001b[0m       \u001b[32m0.5699\u001b[0m        \u001b[35m1.2367\u001b[0m  1.3242\n",
            "     14        \u001b[36m0.9963\u001b[0m       \u001b[32m0.5728\u001b[0m        \u001b[35m1.2301\u001b[0m  1.2918\n",
            "     15        \u001b[36m0.9871\u001b[0m       \u001b[32m0.5739\u001b[0m        \u001b[35m1.2255\u001b[0m  1.4237\n",
            "     16        \u001b[36m0.9791\u001b[0m       \u001b[32m0.5757\u001b[0m        \u001b[35m1.2223\u001b[0m  2.3310\n",
            "     17        \u001b[36m0.9720\u001b[0m       \u001b[32m0.5779\u001b[0m        \u001b[35m1.2186\u001b[0m  1.9111\n",
            "     18        \u001b[36m0.9656\u001b[0m       \u001b[32m0.5800\u001b[0m        \u001b[35m1.2162\u001b[0m  1.2814\n",
            "     19        \u001b[36m0.9598\u001b[0m       \u001b[32m0.5807\u001b[0m        \u001b[35m1.2150\u001b[0m  1.3154\n",
            "     20        \u001b[36m0.9545\u001b[0m       \u001b[32m0.5815\u001b[0m        \u001b[35m1.2138\u001b[0m  1.2897\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.1489\u001b[0m       \u001b[32m0.1063\u001b[0m        \u001b[35m2.8778\u001b[0m  1.3127\n",
            "      2        \u001b[36m2.8643\u001b[0m       \u001b[32m0.1190\u001b[0m        \u001b[35m2.8337\u001b[0m  2.1165\n",
            "      3        2.8788       0.1096        2.8422  1.5821\n",
            "      4        3.2480       0.0397        3.2771  1.3144\n",
            "      5        3.2742       0.0397        3.2656  1.3152\n",
            "      6        3.2729       0.0397        3.2656  1.3360\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.4425\u001b[0m       \u001b[32m0.0393\u001b[0m        \u001b[35m3.2645\u001b[0m  1.4553\n",
            "      2        \u001b[36m3.2713\u001b[0m       0.0393        3.2645  2.1636\n",
            "      3        3.2717       0.0393        3.2646  1.3113\n",
            "      4        3.2719       0.0393        3.2646  1.3237\n",
            "      5        3.2720       0.0393        3.2646  1.3316\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.3012\u001b[0m       \u001b[32m0.0703\u001b[0m        \u001b[35m3.2414\u001b[0m  1.3579\n",
            "      2        \u001b[36m3.1827\u001b[0m       \u001b[32m0.0732\u001b[0m        \u001b[35m3.1227\u001b[0m  1.6602\n",
            "      3        \u001b[36m3.1178\u001b[0m       0.0674        3.5735  1.8931\n",
            "      4        3.2060       0.0732        3.1326  1.2967\n",
            "      5        3.2330       0.0393        3.2660  1.3208\n",
            "      6        3.2735       0.0393        3.2659  1.3018\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.6437\u001b[0m       \u001b[32m0.0397\u001b[0m        \u001b[35m3.2640\u001b[0m  4.9615\n",
            "      2        \u001b[36m3.2712\u001b[0m       0.0397        3.2647  2.6404\n",
            "      3        3.2718       0.0397        3.2650  1.3181\n",
            "      4        3.2721       0.0397        3.2652  1.3148\n",
            "      5        3.2723       0.0397        3.2654  1.3188\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.3332\u001b[0m       \u001b[32m0.0393\u001b[0m        \u001b[35m3.2639\u001b[0m  1.3407\n",
            "      2        \u001b[36m3.2720\u001b[0m       0.0393        3.2644  2.4042\n",
            "      3        3.2723       0.0393        3.2646  1.6271\n",
            "      4        3.2724       0.0393        3.2646  2.1201\n",
            "      5        3.2725       0.0393        3.2646  1.5869\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.4965\u001b[0m       \u001b[32m0.0634\u001b[0m        \u001b[35m3.0848\u001b[0m  1.3259\n",
            "      2        \u001b[36m3.0909\u001b[0m       0.0548        \u001b[35m3.0847\u001b[0m  1.3651\n",
            "      3        \u001b[36m3.0723\u001b[0m       \u001b[32m0.0656\u001b[0m        3.0901  2.1753\n",
            "      4        3.1317       \u001b[32m0.0735\u001b[0m        3.1314  1.4386\n",
            "      5        3.1206       \u001b[32m0.0739\u001b[0m        3.1137  1.8580\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.2509\u001b[0m       \u001b[32m0.0714\u001b[0m        \u001b[35m3.2403\u001b[0m  2.2110\n",
            "      2        \u001b[36m3.2313\u001b[0m       \u001b[32m0.1373\u001b[0m        \u001b[35m3.2203\u001b[0m  2.7569\n",
            "      3        \u001b[36m3.2092\u001b[0m       \u001b[32m0.1882\u001b[0m        \u001b[35m3.1958\u001b[0m  2.0732\n",
            "      4        \u001b[36m3.1819\u001b[0m       \u001b[32m0.2022\u001b[0m        \u001b[35m3.1651\u001b[0m  1.8104\n",
            "      5        \u001b[36m3.1466\u001b[0m       \u001b[32m0.2091\u001b[0m        \u001b[35m3.1247\u001b[0m  1.7442\n",
            "      6        \u001b[36m3.1006\u001b[0m       \u001b[32m0.2156\u001b[0m        \u001b[35m3.0731\u001b[0m  1.8226\n",
            "      7        \u001b[36m3.0432\u001b[0m       0.2076        \u001b[35m3.0102\u001b[0m  3.2665\n",
            "      8        \u001b[36m2.9746\u001b[0m       0.1947        \u001b[35m2.9373\u001b[0m  2.1913\n",
            "      9        \u001b[36m2.8980\u001b[0m       \u001b[32m0.2304\u001b[0m        \u001b[35m2.8579\u001b[0m  1.2613\n",
            "     10        \u001b[36m2.8151\u001b[0m       \u001b[32m0.3385\u001b[0m        \u001b[35m2.7726\u001b[0m  1.2819\n",
            "     11        \u001b[36m2.7272\u001b[0m       \u001b[32m0.3814\u001b[0m        \u001b[35m2.6836\u001b[0m  1.2859\n",
            "     12        \u001b[36m2.6378\u001b[0m       \u001b[32m0.3958\u001b[0m        \u001b[35m2.5949\u001b[0m  1.2650\n",
            "     13        \u001b[36m2.5497\u001b[0m       \u001b[32m0.4131\u001b[0m        \u001b[35m2.5084\u001b[0m  1.2553\n",
            "     14        \u001b[36m2.4640\u001b[0m       \u001b[32m0.4311\u001b[0m        \u001b[35m2.4242\u001b[0m  1.2584\n",
            "     15        \u001b[36m2.3806\u001b[0m       \u001b[32m0.4412\u001b[0m        \u001b[35m2.3423\u001b[0m  1.6441\n",
            "     16        \u001b[36m2.2996\u001b[0m       \u001b[32m0.4492\u001b[0m        \u001b[35m2.2626\u001b[0m  1.7976\n",
            "     17        \u001b[36m2.2211\u001b[0m       \u001b[32m0.4618\u001b[0m        \u001b[35m2.1855\u001b[0m  1.2564\n",
            "     18        \u001b[36m2.1453\u001b[0m       \u001b[32m0.4694\u001b[0m        \u001b[35m2.1111\u001b[0m  1.2892\n",
            "     19        \u001b[36m2.0727\u001b[0m       \u001b[32m0.4852\u001b[0m        \u001b[35m2.0401\u001b[0m  1.2734\n",
            "     20        \u001b[36m2.0036\u001b[0m       \u001b[32m0.4978\u001b[0m        \u001b[35m1.9728\u001b[0m  1.2672\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.2555\u001b[0m       \u001b[32m0.0656\u001b[0m        \u001b[35m3.2426\u001b[0m  1.2846\n",
            "      2        \u001b[36m3.2332\u001b[0m       \u001b[32m0.0908\u001b[0m        \u001b[35m3.2225\u001b[0m  1.6936\n",
            "      3        \u001b[36m3.2113\u001b[0m       \u001b[32m0.1316\u001b[0m        \u001b[35m3.1988\u001b[0m  1.7972\n",
            "      4        \u001b[36m3.1838\u001b[0m       \u001b[32m0.1503\u001b[0m        \u001b[35m3.1681\u001b[0m  1.3104\n",
            "      5        \u001b[36m3.1476\u001b[0m       \u001b[32m0.1590\u001b[0m        \u001b[35m3.1277\u001b[0m  1.2726\n",
            "      6        \u001b[36m3.1006\u001b[0m       \u001b[32m0.1651\u001b[0m        \u001b[35m3.0763\u001b[0m  1.2803\n",
            "      7        \u001b[36m3.0430\u001b[0m       \u001b[32m0.1810\u001b[0m        \u001b[35m3.0154\u001b[0m  1.3218\n",
            "      8        \u001b[36m2.9766\u001b[0m       \u001b[32m0.2004\u001b[0m        \u001b[35m2.9468\u001b[0m  1.2941\n",
            "      9        \u001b[36m2.9033\u001b[0m       \u001b[32m0.2372\u001b[0m        \u001b[35m2.8715\u001b[0m  1.2736\n",
            "     10        \u001b[36m2.8239\u001b[0m       \u001b[32m0.2614\u001b[0m        \u001b[35m2.7903\u001b[0m  1.2758\n",
            "     11        \u001b[36m2.7392\u001b[0m       \u001b[32m0.2870\u001b[0m        \u001b[35m2.7041\u001b[0m  1.7169\n",
            "     12        \u001b[36m2.6508\u001b[0m       \u001b[32m0.3100\u001b[0m        \u001b[35m2.6158\u001b[0m  1.7234\n",
            "     13        \u001b[36m2.5621\u001b[0m       \u001b[32m0.3464\u001b[0m        \u001b[35m2.5291\u001b[0m  1.2720\n",
            "     14        \u001b[36m2.4755\u001b[0m       \u001b[32m0.3601\u001b[0m        \u001b[35m2.4451\u001b[0m  1.2769\n",
            "     15        \u001b[36m2.3917\u001b[0m       \u001b[32m0.3861\u001b[0m        \u001b[35m2.3640\u001b[0m  1.2860\n",
            "     16        \u001b[36m2.3108\u001b[0m       \u001b[32m0.4019\u001b[0m        \u001b[35m2.2860\u001b[0m  1.2308\n",
            "     17        \u001b[36m2.2336\u001b[0m       \u001b[32m0.4254\u001b[0m        \u001b[35m2.2120\u001b[0m  1.2812\n",
            "     18        \u001b[36m2.1610\u001b[0m       \u001b[32m0.4423\u001b[0m        \u001b[35m2.1429\u001b[0m  1.2885\n",
            "     19        \u001b[36m2.0936\u001b[0m       \u001b[32m0.4600\u001b[0m        \u001b[35m2.0791\u001b[0m  1.2906\n",
            "     20        \u001b[36m2.0314\u001b[0m       \u001b[32m0.4776\u001b[0m        \u001b[35m2.0200\u001b[0m  2.5372\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.2533\u001b[0m       \u001b[32m0.0761\u001b[0m        \u001b[35m3.2426\u001b[0m  1.3076\n",
            "      2        \u001b[36m3.2319\u001b[0m       \u001b[32m0.0847\u001b[0m        \u001b[35m3.2211\u001b[0m  1.2500\n",
            "      3        \u001b[36m3.2083\u001b[0m       \u001b[32m0.0851\u001b[0m        \u001b[35m3.1953\u001b[0m  1.2565\n",
            "      4        \u001b[36m3.1782\u001b[0m       \u001b[32m0.0912\u001b[0m        \u001b[35m3.1615\u001b[0m  1.2749\n",
            "      5        \u001b[36m3.1389\u001b[0m       \u001b[32m0.1262\u001b[0m        \u001b[35m3.1181\u001b[0m  1.2479\n",
            "      6        \u001b[36m3.0901\u001b[0m       \u001b[32m0.1298\u001b[0m        \u001b[35m3.0662\u001b[0m  1.2410\n",
            "      7        \u001b[36m3.0336\u001b[0m       0.1269        \u001b[35m3.0083\u001b[0m  1.7908\n",
            "      8        \u001b[36m2.9723\u001b[0m       \u001b[32m0.1431\u001b[0m        \u001b[35m2.9467\u001b[0m  1.6826\n",
            "      9        \u001b[36m2.9080\u001b[0m       \u001b[32m0.1864\u001b[0m        \u001b[35m2.8819\u001b[0m  1.2396\n",
            "     10        \u001b[36m2.8399\u001b[0m       \u001b[32m0.2300\u001b[0m        \u001b[35m2.8116\u001b[0m  1.2543\n",
            "     11        \u001b[36m2.7654\u001b[0m       \u001b[32m0.2581\u001b[0m        \u001b[35m2.7339\u001b[0m  1.2647\n",
            "     12        \u001b[36m2.6838\u001b[0m       \u001b[32m0.2714\u001b[0m        \u001b[35m2.6501\u001b[0m  1.3011\n",
            "     13        \u001b[36m2.5979\u001b[0m       \u001b[32m0.2877\u001b[0m        \u001b[35m2.5641\u001b[0m  1.2866\n",
            "     14        \u001b[36m2.5108\u001b[0m       \u001b[32m0.3064\u001b[0m        \u001b[35m2.4786\u001b[0m  1.3138\n",
            "     15        \u001b[36m2.4243\u001b[0m       \u001b[32m0.3345\u001b[0m        \u001b[35m2.3944\u001b[0m  1.2725\n",
            "     16        \u001b[36m2.3392\u001b[0m       \u001b[32m0.3677\u001b[0m        \u001b[35m2.3123\u001b[0m  1.8396\n",
            "     17        \u001b[36m2.2562\u001b[0m       \u001b[32m0.3839\u001b[0m        \u001b[35m2.2326\u001b[0m  1.6422\n",
            "     18        \u001b[36m2.1758\u001b[0m       \u001b[32m0.4048\u001b[0m        \u001b[35m2.1558\u001b[0m  1.2880\n",
            "     19        \u001b[36m2.0987\u001b[0m       \u001b[32m0.4167\u001b[0m        \u001b[35m2.0825\u001b[0m  1.2881\n",
            "     20        \u001b[36m2.0252\u001b[0m       \u001b[32m0.4272\u001b[0m        \u001b[35m2.0129\u001b[0m  1.2911\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.2511\u001b[0m       \u001b[32m0.0490\u001b[0m        \u001b[35m3.2363\u001b[0m  2.0713\n",
            "      2        \u001b[36m3.2210\u001b[0m       \u001b[32m0.0519\u001b[0m        \u001b[35m3.2030\u001b[0m  1.4690\n",
            "      3        \u001b[36m3.1794\u001b[0m       \u001b[32m0.0584\u001b[0m        \u001b[35m3.1523\u001b[0m  1.3070\n",
            "      4        \u001b[36m3.1191\u001b[0m       \u001b[32m0.0707\u001b[0m        \u001b[35m3.0843\u001b[0m  1.3381\n",
            "      5        \u001b[36m3.0475\u001b[0m       \u001b[32m0.1125\u001b[0m        \u001b[35m3.0136\u001b[0m  1.2781\n",
            "      6        \u001b[36m2.9827\u001b[0m       \u001b[32m0.1561\u001b[0m        \u001b[35m2.9568\u001b[0m  1.2377\n",
            "      7        \u001b[36m2.9321\u001b[0m       \u001b[32m0.1741\u001b[0m        \u001b[35m2.9115\u001b[0m  1.2964\n",
            "      8        \u001b[36m2.8886\u001b[0m       \u001b[32m0.2062\u001b[0m        \u001b[35m2.8693\u001b[0m  1.2991\n",
            "      9        \u001b[36m2.8453\u001b[0m       \u001b[32m0.2541\u001b[0m        \u001b[35m2.8246\u001b[0m  1.3880\n",
            "     10        \u001b[36m2.7977\u001b[0m       \u001b[32m0.2808\u001b[0m        \u001b[35m2.7748\u001b[0m  2.0702\n",
            "     11        \u001b[36m2.7447\u001b[0m       \u001b[32m0.3097\u001b[0m        \u001b[35m2.7194\u001b[0m  1.3301\n",
            "     12        \u001b[36m2.6862\u001b[0m       \u001b[32m0.3266\u001b[0m        \u001b[35m2.6593\u001b[0m  1.2880\n",
            "     13        \u001b[36m2.6243\u001b[0m       \u001b[32m0.3414\u001b[0m        \u001b[35m2.5971\u001b[0m  1.4645\n",
            "     14        \u001b[36m2.5615\u001b[0m       \u001b[32m0.3544\u001b[0m        \u001b[35m2.5350\u001b[0m  2.5622\n",
            "     15        \u001b[36m2.4996\u001b[0m       \u001b[32m0.3681\u001b[0m        \u001b[35m2.4741\u001b[0m  2.7254\n",
            "     16        \u001b[36m2.4388\u001b[0m       \u001b[32m0.3828\u001b[0m        \u001b[35m2.4139\u001b[0m  1.6630\n",
            "     17        \u001b[36m2.3783\u001b[0m       \u001b[32m0.3955\u001b[0m        \u001b[35m2.3540\u001b[0m  1.9444\n",
            "     18        \u001b[36m2.3180\u001b[0m       \u001b[32m0.4027\u001b[0m        \u001b[35m2.2942\u001b[0m  1.7428\n",
            "     19        \u001b[36m2.2577\u001b[0m       \u001b[32m0.4095\u001b[0m        \u001b[35m2.2343\u001b[0m  1.9747\n",
            "     20        \u001b[36m2.1975\u001b[0m       \u001b[32m0.4203\u001b[0m        \u001b[35m2.1749\u001b[0m  1.2957\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.2544\u001b[0m       \u001b[32m0.0750\u001b[0m        \u001b[35m3.2421\u001b[0m  1.8189\n",
            "      2        \u001b[36m3.2286\u001b[0m       \u001b[32m0.0753\u001b[0m        \u001b[35m3.2141\u001b[0m  1.3203\n",
            "      3        \u001b[36m3.1946\u001b[0m       \u001b[32m0.1035\u001b[0m        \u001b[35m3.1732\u001b[0m  1.2583\n",
            "      4        \u001b[36m3.1435\u001b[0m       \u001b[32m0.1395\u001b[0m        \u001b[35m3.1132\u001b[0m  1.3374\n",
            "      5        \u001b[36m3.0749\u001b[0m       \u001b[32m0.1464\u001b[0m        \u001b[35m3.0415\u001b[0m  1.2942\n",
            "      6        \u001b[36m3.0038\u001b[0m       \u001b[32m0.1565\u001b[0m        \u001b[35m2.9773\u001b[0m  1.2877\n",
            "      7        \u001b[36m2.9453\u001b[0m       \u001b[32m0.2127\u001b[0m        \u001b[35m2.9275\u001b[0m  1.7349\n",
            "      8        \u001b[36m2.8989\u001b[0m       \u001b[32m0.2596\u001b[0m        \u001b[35m2.8856\u001b[0m  3.0293\n",
            "      9        \u001b[36m2.8568\u001b[0m       \u001b[32m0.2877\u001b[0m        \u001b[35m2.8448\u001b[0m  2.5283\n",
            "     10        \u001b[36m2.8142\u001b[0m       \u001b[32m0.3039\u001b[0m        \u001b[35m2.8013\u001b[0m  2.2101\n",
            "     11        \u001b[36m2.7675\u001b[0m       0.2870        \u001b[35m2.7523\u001b[0m  2.1389\n",
            "     12        \u001b[36m2.7147\u001b[0m       0.2970        \u001b[35m2.6964\u001b[0m  1.3949\n",
            "     13        \u001b[36m2.6541\u001b[0m       \u001b[32m0.3129\u001b[0m        \u001b[35m2.6324\u001b[0m  2.0795\n",
            "     14        \u001b[36m2.5859\u001b[0m       \u001b[32m0.3335\u001b[0m        \u001b[35m2.5614\u001b[0m  3.8591\n",
            "     15        \u001b[36m2.5113\u001b[0m       \u001b[32m0.3612\u001b[0m        \u001b[35m2.4846\u001b[0m  1.3213\n",
            "     16        \u001b[36m2.4319\u001b[0m       \u001b[32m0.3882\u001b[0m        \u001b[35m2.4040\u001b[0m  1.3156\n",
            "     17        \u001b[36m2.3500\u001b[0m       \u001b[32m0.4059\u001b[0m        \u001b[35m2.3218\u001b[0m  1.2979\n",
            "     18        \u001b[36m2.2678\u001b[0m       \u001b[32m0.4178\u001b[0m        \u001b[35m2.2403\u001b[0m  1.3231\n",
            "     19        \u001b[36m2.1873\u001b[0m       \u001b[32m0.4319\u001b[0m        \u001b[35m2.1615\u001b[0m  1.3166\n",
            "     20        \u001b[36m2.1105\u001b[0m       \u001b[32m0.4384\u001b[0m        \u001b[35m2.0869\u001b[0m  1.2848\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.2513\u001b[0m       \u001b[32m0.0382\u001b[0m        \u001b[35m3.2324\u001b[0m  1.5949\n",
            "      2        \u001b[36m3.2131\u001b[0m       0.0382        \u001b[35m3.1926\u001b[0m  1.2620\n",
            "      3        \u001b[36m3.1649\u001b[0m       \u001b[32m0.0389\u001b[0m        \u001b[35m3.1361\u001b[0m  1.2469\n",
            "      4        \u001b[36m3.0996\u001b[0m       \u001b[32m0.0418\u001b[0m        \u001b[35m3.0669\u001b[0m  1.2886\n",
            "      5        \u001b[36m3.0315\u001b[0m       \u001b[32m0.1280\u001b[0m        \u001b[35m3.0068\u001b[0m  1.2848\n",
            "      6        \u001b[36m2.9779\u001b[0m       \u001b[32m0.2076\u001b[0m        \u001b[35m2.9627\u001b[0m  1.7808\n",
            "      7        \u001b[36m2.9366\u001b[0m       \u001b[32m0.2116\u001b[0m        \u001b[35m2.9264\u001b[0m  2.3308\n",
            "      8        \u001b[36m2.9001\u001b[0m       \u001b[32m0.2314\u001b[0m        \u001b[35m2.8919\u001b[0m  1.8221\n",
            "      9        \u001b[36m2.8640\u001b[0m       \u001b[32m0.2466\u001b[0m        \u001b[35m2.8562\u001b[0m  2.0422\n",
            "     10        \u001b[36m2.8257\u001b[0m       \u001b[32m0.2570\u001b[0m        \u001b[35m2.8168\u001b[0m  2.0817\n",
            "     11        \u001b[36m2.7832\u001b[0m       \u001b[32m0.2754\u001b[0m        \u001b[35m2.7725\u001b[0m  1.7062\n",
            "     12        \u001b[36m2.7354\u001b[0m       \u001b[32m0.2898\u001b[0m        \u001b[35m2.7230\u001b[0m  1.4008\n",
            "     13        \u001b[36m2.6828\u001b[0m       \u001b[32m0.3118\u001b[0m        \u001b[35m2.6691\u001b[0m  3.1753\n",
            "     14        \u001b[36m2.6265\u001b[0m       \u001b[32m0.3342\u001b[0m        \u001b[35m2.6124\u001b[0m  1.3085\n",
            "     15        \u001b[36m2.5680\u001b[0m       \u001b[32m0.3450\u001b[0m        \u001b[35m2.5545\u001b[0m  1.2995\n",
            "     16        \u001b[36m2.5087\u001b[0m       \u001b[32m0.3518\u001b[0m        \u001b[35m2.4963\u001b[0m  1.2952\n",
            "     17        \u001b[36m2.4491\u001b[0m       \u001b[32m0.3652\u001b[0m        \u001b[35m2.4379\u001b[0m  1.2867\n",
            "     18        \u001b[36m2.3888\u001b[0m       \u001b[32m0.3782\u001b[0m        \u001b[35m2.3787\u001b[0m  1.3233\n",
            "     19        \u001b[36m2.3275\u001b[0m       \u001b[32m0.3893\u001b[0m        \u001b[35m2.3183\u001b[0m  1.2918\n",
            "     20        \u001b[36m2.2649\u001b[0m       \u001b[32m0.4027\u001b[0m        \u001b[35m2.2568\u001b[0m  1.3087\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.4065\u001b[0m       \u001b[32m0.6846\u001b[0m        \u001b[35m0.8679\u001b[0m  1.3642\n",
            "      2        \u001b[36m0.8190\u001b[0m       \u001b[32m0.6990\u001b[0m        \u001b[35m0.8035\u001b[0m  1.3920\n",
            "      3        \u001b[36m0.7577\u001b[0m       \u001b[32m0.7123\u001b[0m        \u001b[35m0.8000\u001b[0m  2.1022\n",
            "      4        \u001b[36m0.7230\u001b[0m       \u001b[32m0.7249\u001b[0m        \u001b[35m0.7749\u001b[0m  1.3393\n",
            "      5        \u001b[36m0.6997\u001b[0m       \u001b[32m0.7289\u001b[0m        0.7843  1.3424\n",
            "      6        \u001b[36m0.6741\u001b[0m       \u001b[32m0.7325\u001b[0m        0.7821  1.8273\n",
            "      7        \u001b[36m0.6548\u001b[0m       \u001b[32m0.7343\u001b[0m        0.7824  1.9007\n",
            "      8        \u001b[36m0.6359\u001b[0m       0.7336        0.7868  1.4257\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3874\u001b[0m       \u001b[32m0.6716\u001b[0m        \u001b[35m0.8815\u001b[0m  1.3635\n",
            "      2        \u001b[36m0.8342\u001b[0m       \u001b[32m0.7051\u001b[0m        \u001b[35m0.8131\u001b[0m  1.3750\n",
            "      3        \u001b[36m0.7756\u001b[0m       0.7004        \u001b[35m0.8004\u001b[0m  1.3324\n",
            "      4        \u001b[36m0.7349\u001b[0m       0.7048        \u001b[35m0.7979\u001b[0m  2.1350\n",
            "      5        \u001b[36m0.7043\u001b[0m       \u001b[32m0.7138\u001b[0m        \u001b[35m0.7955\u001b[0m  1.4303\n",
            "      6        \u001b[36m0.6885\u001b[0m       \u001b[32m0.7149\u001b[0m        0.8137  1.3137\n",
            "      7        \u001b[36m0.6667\u001b[0m       0.7109        0.8232  1.2984\n",
            "      8        \u001b[36m0.6639\u001b[0m       0.7044        0.8604  1.4184\n",
            "      9        \u001b[36m0.6493\u001b[0m       0.7033        0.8621  1.3931\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3822\u001b[0m       \u001b[32m0.6676\u001b[0m        \u001b[35m0.8986\u001b[0m  1.9471\n",
            "      2        \u001b[36m0.8492\u001b[0m       \u001b[32m0.6763\u001b[0m        \u001b[35m0.8840\u001b[0m  1.3423\n",
            "      3        \u001b[36m0.7838\u001b[0m       \u001b[32m0.6914\u001b[0m        \u001b[35m0.8387\u001b[0m  1.3280\n",
            "      4        \u001b[36m0.7425\u001b[0m       \u001b[32m0.6972\u001b[0m        \u001b[35m0.8118\u001b[0m  1.3424\n",
            "      5        \u001b[36m0.7091\u001b[0m       0.6921        0.8275  1.3317\n",
            "      6        \u001b[36m0.6887\u001b[0m       \u001b[32m0.7037\u001b[0m        \u001b[35m0.8028\u001b[0m  1.4196\n",
            "      7        \u001b[36m0.6629\u001b[0m       0.6950        0.8422  1.5452\n",
            "      8        \u001b[36m0.6456\u001b[0m       0.6947        0.8429  2.5232\n",
            "      9        \u001b[36m0.6322\u001b[0m       \u001b[32m0.7058\u001b[0m        0.8207  2.8296\n",
            "     10        \u001b[36m0.6144\u001b[0m       0.6965        0.9019  2.1505\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.7074\u001b[0m       \u001b[32m0.5797\u001b[0m        \u001b[35m1.1680\u001b[0m  1.7675\n",
            "      2        \u001b[36m1.0747\u001b[0m       \u001b[32m0.6125\u001b[0m        \u001b[35m1.1074\u001b[0m  1.7565\n",
            "      3        \u001b[36m0.9983\u001b[0m       \u001b[32m0.6236\u001b[0m        \u001b[35m1.0853\u001b[0m  1.9560\n",
            "      4        \u001b[36m0.9514\u001b[0m       0.6175        1.1138  2.2854\n",
            "      5        \u001b[36m0.9243\u001b[0m       0.6136        1.1214  1.8983\n",
            "      6        \u001b[36m0.8872\u001b[0m       0.6154        1.1390  2.7858\n",
            "      7        \u001b[36m0.8560\u001b[0m       0.6190        1.1547  1.7219\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6808\u001b[0m       \u001b[32m0.5937\u001b[0m        \u001b[35m1.1364\u001b[0m  1.9079\n",
            "      2        \u001b[36m1.0886\u001b[0m       \u001b[32m0.6085\u001b[0m        \u001b[35m1.0846\u001b[0m  2.2960\n",
            "      3        \u001b[36m1.0025\u001b[0m       \u001b[32m0.6157\u001b[0m        \u001b[35m1.0758\u001b[0m  1.3529\n",
            "      4        \u001b[36m0.9478\u001b[0m       0.6107        1.1043  2.4454\n",
            "      5        \u001b[36m0.9255\u001b[0m       \u001b[32m0.6265\u001b[0m        1.0863  2.0044\n",
            "      6        \u001b[36m0.8837\u001b[0m       0.6240        1.0927  3.6459\n",
            "      7        \u001b[36m0.8525\u001b[0m       0.6096        1.1631  2.1860\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6701\u001b[0m       \u001b[32m0.5335\u001b[0m        \u001b[35m1.3552\u001b[0m  1.3013\n",
            "      2        \u001b[36m1.1149\u001b[0m       \u001b[32m0.6002\u001b[0m        \u001b[35m1.1622\u001b[0m  1.3023\n",
            "      3        \u001b[36m1.0186\u001b[0m       \u001b[32m0.6121\u001b[0m        \u001b[35m1.1498\u001b[0m  1.2967\n",
            "      4        \u001b[36m0.9777\u001b[0m       0.6118        1.1592  1.3362\n",
            "      5        \u001b[36m0.9356\u001b[0m       0.6118        1.1727  2.5832\n",
            "      6        \u001b[36m0.9068\u001b[0m       \u001b[32m0.6132\u001b[0m        1.2287  1.3178\n",
            "      7        \u001b[36m0.8815\u001b[0m       \u001b[32m0.6179\u001b[0m        1.2359  1.7490\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.2484\u001b[0m       \u001b[32m0.1038\u001b[0m        \u001b[35m3.2314\u001b[0m  1.6494\n",
            "      2        \u001b[36m3.2112\u001b[0m       \u001b[32m0.1402\u001b[0m        \u001b[35m3.1892\u001b[0m  1.6766\n",
            "      3        \u001b[36m3.1623\u001b[0m       \u001b[32m0.1471\u001b[0m        \u001b[35m3.1336\u001b[0m  1.5954\n",
            "      4        \u001b[36m3.1006\u001b[0m       0.1428        \u001b[35m3.0660\u001b[0m  2.5853\n",
            "      5        \u001b[36m3.0276\u001b[0m       0.1435        \u001b[35m2.9880\u001b[0m  1.8465\n",
            "      6        \u001b[36m2.9457\u001b[0m       \u001b[32m0.1550\u001b[0m        \u001b[35m2.9029\u001b[0m  1.7679\n",
            "      7        \u001b[36m2.8572\u001b[0m       \u001b[32m0.1965\u001b[0m        \u001b[35m2.8111\u001b[0m  2.2382\n",
            "      8        \u001b[36m2.7610\u001b[0m       \u001b[32m0.2693\u001b[0m        \u001b[35m2.7106\u001b[0m  1.8640\n",
            "      9        \u001b[36m2.6566\u001b[0m       \u001b[32m0.3280\u001b[0m        \u001b[35m2.6033\u001b[0m  1.6562\n",
            "     10        \u001b[36m2.5479\u001b[0m       \u001b[32m0.3699\u001b[0m        \u001b[35m2.4948\u001b[0m  1.6565\n",
            "     11        \u001b[36m2.4410\u001b[0m       \u001b[32m0.3890\u001b[0m        \u001b[35m2.3909\u001b[0m  2.7376\n",
            "     12        \u001b[36m2.3404\u001b[0m       \u001b[32m0.4074\u001b[0m        \u001b[35m2.2948\u001b[0m  2.0518\n",
            "     13        \u001b[36m2.2487\u001b[0m       \u001b[32m0.4362\u001b[0m        \u001b[35m2.2085\u001b[0m  2.0581\n",
            "     14        \u001b[36m2.1671\u001b[0m       \u001b[32m0.4560\u001b[0m        \u001b[35m2.1323\u001b[0m  2.1337\n",
            "     15        \u001b[36m2.0950\u001b[0m       \u001b[32m0.4755\u001b[0m        \u001b[35m2.0648\u001b[0m  1.2961\n",
            "     16        \u001b[36m2.0307\u001b[0m       \u001b[32m0.4957\u001b[0m        \u001b[35m2.0040\u001b[0m  1.2482\n",
            "     17        \u001b[36m1.9723\u001b[0m       \u001b[32m0.5087\u001b[0m        \u001b[35m1.9479\u001b[0m  1.3783\n",
            "     18        \u001b[36m1.9177\u001b[0m       \u001b[32m0.5242\u001b[0m        \u001b[35m1.8948\u001b[0m  2.0393\n",
            "     19        \u001b[36m1.8656\u001b[0m       \u001b[32m0.5371\u001b[0m        \u001b[35m1.8436\u001b[0m  1.3542\n",
            "     20        \u001b[36m1.8150\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m1.7936\u001b[0m  1.2936\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.2413\u001b[0m       \u001b[32m0.0995\u001b[0m        \u001b[35m3.2222\u001b[0m  1.2845\n",
            "      2        \u001b[36m3.2034\u001b[0m       \u001b[32m0.1665\u001b[0m        \u001b[35m3.1833\u001b[0m  1.2812\n",
            "      3        \u001b[36m3.1601\u001b[0m       \u001b[32m0.1806\u001b[0m        \u001b[35m3.1357\u001b[0m  1.2866\n",
            "      4        \u001b[36m3.1066\u001b[0m       \u001b[32m0.1878\u001b[0m        \u001b[35m3.0782\u001b[0m  1.7734\n",
            "      5        \u001b[36m3.0440\u001b[0m       \u001b[32m0.2195\u001b[0m        \u001b[35m3.0130\u001b[0m  1.6572\n",
            "      6        \u001b[36m2.9744\u001b[0m       \u001b[32m0.2920\u001b[0m        \u001b[35m2.9415\u001b[0m  1.2657\n",
            "      7        \u001b[36m2.8984\u001b[0m       \u001b[32m0.3648\u001b[0m        \u001b[35m2.8633\u001b[0m  1.2784\n",
            "      8        \u001b[36m2.8154\u001b[0m       \u001b[32m0.4056\u001b[0m        \u001b[35m2.7775\u001b[0m  1.2674\n",
            "      9        \u001b[36m2.7250\u001b[0m       \u001b[32m0.4243\u001b[0m        \u001b[35m2.6851\u001b[0m  1.5579\n",
            "     10        \u001b[36m2.6296\u001b[0m       \u001b[32m0.4362\u001b[0m        \u001b[35m2.5900\u001b[0m  1.9527\n",
            "     11        \u001b[36m2.5332\u001b[0m       \u001b[32m0.4503\u001b[0m        \u001b[35m2.4957\u001b[0m  1.3192\n",
            "     12        \u001b[36m2.4378\u001b[0m       \u001b[32m0.4715\u001b[0m        \u001b[35m2.4025\u001b[0m  1.6629\n",
            "     13        \u001b[36m2.3435\u001b[0m       \u001b[32m0.4953\u001b[0m        \u001b[35m2.3106\u001b[0m  1.8664\n",
            "     14        \u001b[36m2.2514\u001b[0m       \u001b[32m0.5068\u001b[0m        \u001b[35m2.2220\u001b[0m  1.2997\n",
            "     15        \u001b[36m2.1640\u001b[0m       \u001b[32m0.5224\u001b[0m        \u001b[35m2.1390\u001b[0m  1.3404\n",
            "     16        \u001b[36m2.0830\u001b[0m       \u001b[32m0.5364\u001b[0m        \u001b[35m2.0626\u001b[0m  1.3167\n",
            "     17        \u001b[36m2.0085\u001b[0m       \u001b[32m0.5526\u001b[0m        \u001b[35m1.9923\u001b[0m  1.3078\n",
            "     18        \u001b[36m1.9399\u001b[0m       \u001b[32m0.5530\u001b[0m        \u001b[35m1.9270\u001b[0m  1.2985\n",
            "     19        \u001b[36m1.8758\u001b[0m       \u001b[32m0.5595\u001b[0m        \u001b[35m1.8656\u001b[0m  1.3580\n",
            "     20        \u001b[36m1.8152\u001b[0m       \u001b[32m0.5735\u001b[0m        \u001b[35m1.8071\u001b[0m  1.2847\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.2397\u001b[0m       \u001b[32m0.1020\u001b[0m        \u001b[35m3.2168\u001b[0m  1.2650\n",
            "      2        \u001b[36m3.1922\u001b[0m       \u001b[32m0.1305\u001b[0m        \u001b[35m3.1687\u001b[0m  1.2869\n",
            "      3        \u001b[36m3.1401\u001b[0m       \u001b[32m0.1640\u001b[0m        \u001b[35m3.1134\u001b[0m  1.2996\n",
            "      4        \u001b[36m3.0797\u001b[0m       \u001b[32m0.2044\u001b[0m        \u001b[35m3.0495\u001b[0m  1.2760\n",
            "      5        \u001b[36m3.0110\u001b[0m       \u001b[32m0.2448\u001b[0m        \u001b[35m2.9780\u001b[0m  1.2846\n",
            "      6        \u001b[36m2.9352\u001b[0m       \u001b[32m0.3133\u001b[0m        \u001b[35m2.8996\u001b[0m  1.2927\n",
            "      7        \u001b[36m2.8517\u001b[0m       \u001b[32m0.3745\u001b[0m        \u001b[35m2.8124\u001b[0m  1.3651\n",
            "      8        \u001b[36m2.7589\u001b[0m       \u001b[32m0.3922\u001b[0m        \u001b[35m2.7150\u001b[0m  3.3811\n",
            "      9        \u001b[36m2.6568\u001b[0m       0.3720        \u001b[35m2.6097\u001b[0m  1.3063\n",
            "     10        \u001b[36m2.5494\u001b[0m       0.3771        \u001b[35m2.5028\u001b[0m  1.2904\n",
            "     11        \u001b[36m2.4432\u001b[0m       0.3890        \u001b[35m2.4005\u001b[0m  1.2723\n",
            "     12        \u001b[36m2.3425\u001b[0m       \u001b[32m0.4102\u001b[0m        \u001b[35m2.3045\u001b[0m  1.2629\n",
            "     13        \u001b[36m2.2475\u001b[0m       \u001b[32m0.4387\u001b[0m        \u001b[35m2.2140\u001b[0m  1.3128\n",
            "     14        \u001b[36m2.1580\u001b[0m       \u001b[32m0.4575\u001b[0m        \u001b[35m2.1290\u001b[0m  2.4751\n",
            "     15        \u001b[36m2.0742\u001b[0m       \u001b[32m0.4769\u001b[0m        \u001b[35m2.0498\u001b[0m  1.7605\n",
            "     16        \u001b[36m1.9966\u001b[0m       \u001b[32m0.4953\u001b[0m        \u001b[35m1.9769\u001b[0m  1.7480\n",
            "     17        \u001b[36m1.9255\u001b[0m       \u001b[32m0.5144\u001b[0m        \u001b[35m1.9100\u001b[0m  1.3289\n",
            "     18        \u001b[36m1.8603\u001b[0m       \u001b[32m0.5321\u001b[0m        \u001b[35m1.8485\u001b[0m  1.2614\n",
            "     19        \u001b[36m1.8001\u001b[0m       \u001b[32m0.5465\u001b[0m        \u001b[35m1.7914\u001b[0m  1.3041\n",
            "     20        \u001b[36m1.7440\u001b[0m       \u001b[32m0.5541\u001b[0m        \u001b[35m1.7378\u001b[0m  1.4785\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.2490\u001b[0m       \u001b[32m0.0379\u001b[0m        \u001b[35m3.2273\u001b[0m  1.3163\n",
            "      2        \u001b[36m3.2039\u001b[0m       \u001b[32m0.0707\u001b[0m        \u001b[35m3.1775\u001b[0m  1.2836\n",
            "      3        \u001b[36m3.1434\u001b[0m       \u001b[32m0.1125\u001b[0m        \u001b[35m3.1068\u001b[0m  1.2809\n",
            "      4        \u001b[36m3.0649\u001b[0m       \u001b[32m0.1247\u001b[0m        \u001b[35m3.0252\u001b[0m  1.3286\n",
            "      5        \u001b[36m2.9871\u001b[0m       \u001b[32m0.1820\u001b[0m        \u001b[35m2.9545\u001b[0m  1.2879\n",
            "      6        \u001b[36m2.9228\u001b[0m       \u001b[32m0.2415\u001b[0m        \u001b[35m2.8963\u001b[0m  1.2868\n",
            "      7        \u001b[36m2.8669\u001b[0m       \u001b[32m0.3010\u001b[0m        \u001b[35m2.8416\u001b[0m  1.5135\n",
            "      8        \u001b[36m2.8106\u001b[0m       \u001b[32m0.3497\u001b[0m        \u001b[35m2.7835\u001b[0m  1.9991\n",
            "      9        \u001b[36m2.7493\u001b[0m       \u001b[32m0.3864\u001b[0m        \u001b[35m2.7196\u001b[0m  1.2908\n",
            "     10        \u001b[36m2.6817\u001b[0m       \u001b[32m0.4063\u001b[0m        \u001b[35m2.6495\u001b[0m  1.3145\n",
            "     11        \u001b[36m2.6086\u001b[0m       \u001b[32m0.4236\u001b[0m        \u001b[35m2.5750\u001b[0m  1.2704\n",
            "     12        \u001b[36m2.5323\u001b[0m       0.4193        \u001b[35m2.4983\u001b[0m  1.2693\n",
            "     13        \u001b[36m2.4549\u001b[0m       \u001b[32m0.4257\u001b[0m        \u001b[35m2.4216\u001b[0m  1.3464\n",
            "     14        \u001b[36m2.3780\u001b[0m       \u001b[32m0.4344\u001b[0m        \u001b[35m2.3458\u001b[0m  1.2887\n",
            "     15        \u001b[36m2.3022\u001b[0m       \u001b[32m0.4481\u001b[0m        \u001b[35m2.2711\u001b[0m  1.3041\n",
            "     16        \u001b[36m2.2277\u001b[0m       \u001b[32m0.4571\u001b[0m        \u001b[35m2.1981\u001b[0m  1.5964\n",
            "     17        \u001b[36m2.1552\u001b[0m       \u001b[32m0.4596\u001b[0m        \u001b[35m2.1277\u001b[0m  1.9011\n",
            "     18        \u001b[36m2.0856\u001b[0m       \u001b[32m0.4600\u001b[0m        \u001b[35m2.0605\u001b[0m  1.2949\n",
            "     19        \u001b[36m2.0192\u001b[0m       0.4596        \u001b[35m1.9969\u001b[0m  1.3007\n",
            "     20        \u001b[36m1.9567\u001b[0m       \u001b[32m0.4614\u001b[0m        \u001b[35m1.9374\u001b[0m  1.2965\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.2343\u001b[0m       \u001b[32m0.0681\u001b[0m        \u001b[35m3.2007\u001b[0m  1.4852\n",
            "      2        \u001b[36m3.1630\u001b[0m       \u001b[32m0.0746\u001b[0m        \u001b[35m3.1278\u001b[0m  1.9613\n",
            "      3        \u001b[36m3.0819\u001b[0m       \u001b[32m0.0822\u001b[0m        \u001b[35m3.0431\u001b[0m  1.2815\n",
            "      4        \u001b[36m2.9977\u001b[0m       \u001b[32m0.1438\u001b[0m        \u001b[35m2.9668\u001b[0m  1.3320\n",
            "      5        \u001b[36m2.9277\u001b[0m       \u001b[32m0.1680\u001b[0m        \u001b[35m2.9060\u001b[0m  1.2656\n",
            "      6        \u001b[36m2.8699\u001b[0m       \u001b[32m0.2048\u001b[0m        \u001b[35m2.8522\u001b[0m  1.2787\n",
            "      7        \u001b[36m2.8150\u001b[0m       \u001b[32m0.2480\u001b[0m        \u001b[35m2.7973\u001b[0m  1.2836\n",
            "      8        \u001b[36m2.7572\u001b[0m       \u001b[32m0.2866\u001b[0m        \u001b[35m2.7379\u001b[0m  1.3168\n",
            "      9        \u001b[36m2.6947\u001b[0m       \u001b[32m0.3143\u001b[0m        \u001b[35m2.6742\u001b[0m  1.2772\n",
            "     10        \u001b[36m2.6290\u001b[0m       \u001b[32m0.3443\u001b[0m        \u001b[35m2.6085\u001b[0m  1.6216\n",
            "     11        \u001b[36m2.5627\u001b[0m       \u001b[32m0.3713\u001b[0m        \u001b[35m2.5435\u001b[0m  1.9301\n",
            "     12        \u001b[36m2.4979\u001b[0m       \u001b[32m0.3955\u001b[0m        \u001b[35m2.4805\u001b[0m  1.3528\n",
            "     13        \u001b[36m2.4352\u001b[0m       \u001b[32m0.4189\u001b[0m        \u001b[35m2.4194\u001b[0m  1.2961\n",
            "     14        \u001b[36m2.3743\u001b[0m       \u001b[32m0.4308\u001b[0m        \u001b[35m2.3597\u001b[0m  1.3027\n",
            "     15        \u001b[36m2.3148\u001b[0m       \u001b[32m0.4412\u001b[0m        \u001b[35m2.3011\u001b[0m  1.2774\n",
            "     16        \u001b[36m2.2564\u001b[0m       \u001b[32m0.4513\u001b[0m        \u001b[35m2.2434\u001b[0m  1.2969\n",
            "     17        \u001b[36m2.1987\u001b[0m       \u001b[32m0.4636\u001b[0m        \u001b[35m2.1862\u001b[0m  1.2965\n",
            "     18        \u001b[36m2.1416\u001b[0m       \u001b[32m0.4683\u001b[0m        \u001b[35m2.1296\u001b[0m  1.2713\n",
            "     19        \u001b[36m2.0852\u001b[0m       \u001b[32m0.4715\u001b[0m        \u001b[35m2.0735\u001b[0m  1.7367\n",
            "     20        \u001b[36m2.0292\u001b[0m       \u001b[32m0.4802\u001b[0m        \u001b[35m2.0179\u001b[0m  1.7378\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.2475\u001b[0m       \u001b[32m0.0818\u001b[0m        \u001b[35m3.2223\u001b[0m  1.3293\n",
            "      2        \u001b[36m3.1971\u001b[0m       \u001b[32m0.0833\u001b[0m        \u001b[35m3.1675\u001b[0m  1.2726\n",
            "      3        \u001b[36m3.1310\u001b[0m       0.0800        \u001b[35m3.0927\u001b[0m  1.2902\n",
            "      4        \u001b[36m3.0500\u001b[0m       0.0826        \u001b[35m3.0135\u001b[0m  1.7061\n",
            "      5        \u001b[36m2.9750\u001b[0m       \u001b[32m0.1402\u001b[0m        \u001b[35m2.9478\u001b[0m  1.7562\n",
            "      6        \u001b[36m2.9134\u001b[0m       \u001b[32m0.2520\u001b[0m        \u001b[35m2.8929\u001b[0m  1.2897\n",
            "      7        \u001b[36m2.8579\u001b[0m       \u001b[32m0.2848\u001b[0m        \u001b[35m2.8390\u001b[0m  1.3617\n",
            "      8        \u001b[36m2.8008\u001b[0m       \u001b[32m0.2960\u001b[0m        \u001b[35m2.7807\u001b[0m  1.3353\n",
            "      9        \u001b[36m2.7382\u001b[0m       \u001b[32m0.3032\u001b[0m        \u001b[35m2.7163\u001b[0m  1.3237\n",
            "     10        \u001b[36m2.6698\u001b[0m       \u001b[32m0.3125\u001b[0m        \u001b[35m2.6462\u001b[0m  1.3202\n",
            "     11        \u001b[36m2.5970\u001b[0m       \u001b[32m0.3425\u001b[0m        \u001b[35m2.5729\u001b[0m  1.3284\n",
            "     12        \u001b[36m2.5220\u001b[0m       \u001b[32m0.3601\u001b[0m        \u001b[35m2.4984\u001b[0m  1.4170\n",
            "     13        \u001b[36m2.4467\u001b[0m       \u001b[32m0.3684\u001b[0m        \u001b[35m2.4242\u001b[0m  2.3968\n",
            "     14        \u001b[36m2.3720\u001b[0m       \u001b[32m0.3742\u001b[0m        \u001b[35m2.3506\u001b[0m  1.7088\n",
            "     15        \u001b[36m2.2983\u001b[0m       \u001b[32m0.3810\u001b[0m        \u001b[35m2.2783\u001b[0m  1.2563\n",
            "     16        \u001b[36m2.2263\u001b[0m       \u001b[32m0.3908\u001b[0m        \u001b[35m2.2079\u001b[0m  1.2991\n",
            "     17        \u001b[36m2.1567\u001b[0m       \u001b[32m0.4034\u001b[0m        \u001b[35m2.1400\u001b[0m  1.3228\n",
            "     18        \u001b[36m2.0899\u001b[0m       \u001b[32m0.4185\u001b[0m        \u001b[35m2.0750\u001b[0m  1.2757\n",
            "     19        \u001b[36m2.0263\u001b[0m       \u001b[32m0.4221\u001b[0m        \u001b[35m2.0132\u001b[0m  1.2725\n",
            "     20        \u001b[36m1.9660\u001b[0m       \u001b[32m0.4344\u001b[0m        \u001b[35m1.9545\u001b[0m  1.2715\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3052\u001b[0m       \u001b[32m0.6867\u001b[0m        \u001b[35m0.8581\u001b[0m  1.2811\n",
            "      2        \u001b[36m0.8289\u001b[0m       \u001b[32m0.7127\u001b[0m        \u001b[35m0.7918\u001b[0m  1.2672\n",
            "      3        \u001b[36m0.7910\u001b[0m       0.7116        0.7994  1.3148\n",
            "      4        \u001b[36m0.7633\u001b[0m       \u001b[32m0.7167\u001b[0m        0.7988  1.3612\n",
            "      5        \u001b[36m0.7502\u001b[0m       0.7159        0.8248  1.2929\n",
            "      6        \u001b[36m0.7354\u001b[0m       0.7159        \u001b[35m0.7905\u001b[0m  1.2969\n",
            "      7        \u001b[36m0.7247\u001b[0m       0.7167        0.8125  1.3437\n",
            "      8        \u001b[36m0.7090\u001b[0m       0.7152        0.8158  1.7434\n",
            "      9        0.7131       0.7145        0.8214  1.8600\n",
            "     10        \u001b[36m0.6999\u001b[0m       0.6994        0.8770  1.3384\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.3163\u001b[0m       \u001b[32m0.6723\u001b[0m        \u001b[35m0.9002\u001b[0m  1.3174\n",
            "      2        \u001b[36m0.8472\u001b[0m       \u001b[32m0.6947\u001b[0m        \u001b[35m0.8408\u001b[0m  1.2992\n",
            "      3        \u001b[36m0.7882\u001b[0m       0.6925        0.8477  1.3362\n",
            "      4        \u001b[36m0.7745\u001b[0m       \u001b[32m0.6965\u001b[0m        0.8496  1.8543\n",
            "      5        \u001b[36m0.7550\u001b[0m       \u001b[32m0.7015\u001b[0m        \u001b[35m0.8336\u001b[0m  1.7131\n",
            "      6        \u001b[36m0.7502\u001b[0m       0.6994        \u001b[35m0.8265\u001b[0m  1.3148\n",
            "      7        \u001b[36m0.7446\u001b[0m       0.6943        0.8639  1.3289\n",
            "      8        \u001b[36m0.7234\u001b[0m       \u001b[32m0.7055\u001b[0m        0.8664  1.3279\n",
            "      9        \u001b[36m0.7133\u001b[0m       \u001b[32m0.7066\u001b[0m        0.8693  1.3202\n",
            "     10        \u001b[36m0.6919\u001b[0m       0.6983        0.9001  1.2939\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2652\u001b[0m       \u001b[32m0.6734\u001b[0m        \u001b[35m0.9109\u001b[0m  1.4681\n",
            "      2        \u001b[36m0.8534\u001b[0m       0.6669        0.9694  1.3146\n",
            "      3        \u001b[36m0.8295\u001b[0m       \u001b[32m0.6896\u001b[0m        \u001b[35m0.8668\u001b[0m  1.3396\n",
            "      4        \u001b[36m0.7933\u001b[0m       \u001b[32m0.6903\u001b[0m        0.8856  1.3570\n",
            "      5        \u001b[36m0.7620\u001b[0m       0.6846        0.8943  1.3361\n",
            "      6        \u001b[36m0.7329\u001b[0m       0.6849        0.9132  1.3041\n",
            "      7        \u001b[36m0.7279\u001b[0m       0.6795        0.9345  1.3365\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.5846\u001b[0m       \u001b[32m0.5793\u001b[0m        \u001b[35m1.1772\u001b[0m  1.2923\n",
            "      2        \u001b[36m1.0962\u001b[0m       \u001b[32m0.5941\u001b[0m        \u001b[35m1.1651\u001b[0m  1.3202\n",
            "      3        \u001b[36m1.0341\u001b[0m       \u001b[32m0.6013\u001b[0m        \u001b[35m1.1344\u001b[0m  1.3440\n",
            "      4        \u001b[36m0.9943\u001b[0m       0.5955        1.1527  1.3215\n",
            "      5        \u001b[36m0.9669\u001b[0m       0.5991        1.1430  1.4488\n",
            "      6        \u001b[36m0.9641\u001b[0m       0.5973        1.1505  2.1009\n",
            "      7        \u001b[36m0.9330\u001b[0m       0.5995        1.2068  1.3215\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6034\u001b[0m       \u001b[32m0.5703\u001b[0m        \u001b[35m1.2088\u001b[0m  1.2980\n",
            "      2        \u001b[36m1.1005\u001b[0m       \u001b[32m0.5833\u001b[0m        \u001b[35m1.1820\u001b[0m  1.5548\n",
            "      3        \u001b[36m1.0442\u001b[0m       \u001b[32m0.6060\u001b[0m        \u001b[35m1.1470\u001b[0m  2.1105\n",
            "      4        \u001b[36m0.9985\u001b[0m       0.6017        \u001b[35m1.1343\u001b[0m  1.3331\n",
            "      5        \u001b[36m0.9701\u001b[0m       \u001b[32m0.6150\u001b[0m        \u001b[35m1.0983\u001b[0m  1.3136\n",
            "      6        \u001b[36m0.9456\u001b[0m       \u001b[32m0.6204\u001b[0m        1.1100  1.3091\n",
            "      7        \u001b[36m0.9271\u001b[0m       0.6121        1.1269  1.3093\n",
            "      8        \u001b[36m0.9023\u001b[0m       0.6204        1.1704  1.3362\n",
            "      9        \u001b[36m0.8724\u001b[0m       \u001b[32m0.6208\u001b[0m        1.1942  1.2794\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.6239\u001b[0m       \u001b[32m0.5368\u001b[0m        \u001b[35m1.3004\u001b[0m  1.3262\n",
            "      2        \u001b[36m1.1436\u001b[0m       \u001b[32m0.5894\u001b[0m        \u001b[35m1.1626\u001b[0m  1.3114\n",
            "      3        \u001b[36m1.0574\u001b[0m       \u001b[32m0.5934\u001b[0m        1.1909  1.3009\n",
            "      4        \u001b[36m1.0302\u001b[0m       \u001b[32m0.5988\u001b[0m        1.1782  1.3163\n",
            "      5        \u001b[36m0.9921\u001b[0m       \u001b[32m0.6089\u001b[0m        1.1844  1.2711\n",
            "      6        \u001b[36m0.9846\u001b[0m       0.5890        1.2631  1.7825\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m1.2102\u001b[0m       \u001b[32m0.6870\u001b[0m        \u001b[35m0.8539\u001b[0m  1.9281\n",
            "      2        \u001b[36m0.7940\u001b[0m       \u001b[32m0.6880\u001b[0m        \u001b[35m0.8387\u001b[0m  1.9602\n",
            "      3        \u001b[36m0.7471\u001b[0m       \u001b[32m0.7077\u001b[0m        \u001b[35m0.8005\u001b[0m  1.9696\n",
            "      4        \u001b[36m0.7161\u001b[0m       0.7067        0.8018  2.8660\n",
            "      5        \u001b[36m0.6960\u001b[0m       \u001b[32m0.7190\u001b[0m        \u001b[35m0.7970\u001b[0m  1.9514\n",
            "      6        \u001b[36m0.6776\u001b[0m       0.7135        0.8230  2.0098\n",
            "      7        \u001b[36m0.6606\u001b[0m       0.7156        0.8131  2.1037\n",
            "      8        \u001b[36m0.6461\u001b[0m       0.7082        0.8474  2.0908\n",
            "      9        \u001b[36m0.6330\u001b[0m       \u001b[32m0.7200\u001b[0m        0.8493  2.5189\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[('vect',\n",
              "                                        CountVectorizer(analyzer='char',\n",
              "                                                        binary=True,\n",
              "                                                        max_features=100)),\n",
              "                                       ('adjust_datatype',\n",
              "                                        FunctionTransformer(func=<function type_adjust at 0x7d489764d090>)),\n",
              "                                       ('clf',\n",
              "                                        <class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
              "  module=<class '__main__.ClassifierModule_grid'>,\n",
              "))]),\n",
              "             param_grid={'clf__callbacks__EarlyStopping__patience': [5],\n",
              "                         'clf__lr': [0.1, 0.01],\n",
              "                         'clf__module__nonlin': [<function relu at 0x7d49601c0a60>,\n",
              "                                                 <function tanh at 0x7d49601c1480>],\n",
              "                         'clf__module__num_units': [300],\n",
              "                         'clf__optimizer': [<class 'torch.optim.sgd.SGD'>,\n",
              "                                            <class 'torch.optim.adam.Adam'>],\n",
              "                         'vect__ngram_range': [(1, 1), (2, 2)]},\n",
              "             scoring='accuracy', verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
              "                                        CountVectorizer(analyzer=&#x27;char&#x27;,\n",
              "                                                        binary=True,\n",
              "                                                        max_features=100)),\n",
              "                                       (&#x27;adjust_datatype&#x27;,\n",
              "                                        FunctionTransformer(func=&lt;function type_adjust at 0x7d489764d090&gt;)),\n",
              "                                       (&#x27;clf&#x27;,\n",
              "                                        &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=&lt;class &#x27;__main__.ClassifierModule_grid&#x27;&gt;,\n",
              "))]),\n",
              "             param_grid={&#x27;clf__callbacks__EarlyStopping__patience&#x27;: [5],\n",
              "                         &#x27;clf__lr&#x27;: [0.1, 0.01],\n",
              "                         &#x27;clf__module__nonlin&#x27;: [&lt;function relu at 0x7d49601c0a60&gt;,\n",
              "                                                 &lt;function tanh at 0x7d49601c1480&gt;],\n",
              "                         &#x27;clf__module__num_units&#x27;: [300],\n",
              "                         &#x27;clf__optimizer&#x27;: [&lt;class &#x27;torch.optim.sgd.SGD&#x27;&gt;,\n",
              "                                            &lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;],\n",
              "                         &#x27;vect__ngram_range&#x27;: [(1, 1), (2, 2)]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
              "                                        CountVectorizer(analyzer=&#x27;char&#x27;,\n",
              "                                                        binary=True,\n",
              "                                                        max_features=100)),\n",
              "                                       (&#x27;adjust_datatype&#x27;,\n",
              "                                        FunctionTransformer(func=&lt;function type_adjust at 0x7d489764d090&gt;)),\n",
              "                                       (&#x27;clf&#x27;,\n",
              "                                        &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=&lt;class &#x27;__main__.ClassifierModule_grid&#x27;&gt;,\n",
              "))]),\n",
              "             param_grid={&#x27;clf__callbacks__EarlyStopping__patience&#x27;: [5],\n",
              "                         &#x27;clf__lr&#x27;: [0.1, 0.01],\n",
              "                         &#x27;clf__module__nonlin&#x27;: [&lt;function relu at 0x7d49601c0a60&gt;,\n",
              "                                                 &lt;function tanh at 0x7d49601c1480&gt;],\n",
              "                         &#x27;clf__module__num_units&#x27;: [300],\n",
              "                         &#x27;clf__optimizer&#x27;: [&lt;class &#x27;torch.optim.sgd.SGD&#x27;&gt;,\n",
              "                                            &lt;class &#x27;torch.optim.adam.Adam&#x27;&gt;],\n",
              "                         &#x27;vect__ngram_range&#x27;: [(1, 1), (2, 2)]},\n",
              "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;,\n",
              "                 CountVectorizer(analyzer=&#x27;char&#x27;, binary=True,\n",
              "                                 max_features=100)),\n",
              "                (&#x27;adjust_datatype&#x27;,\n",
              "                 FunctionTransformer(func=&lt;function type_adjust at 0x7d489764d090&gt;)),\n",
              "                (&#x27;clf&#x27;,\n",
              "                 &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=&lt;class &#x27;__main__.ClassifierModule_grid&#x27;&gt;,\n",
              "))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer=&#x27;char&#x27;, binary=True, max_features=100)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function type_adjust at 0x7d489764d090&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
              "  module=&lt;class &#x27;__main__.ClassifierModule_grid&#x27;&gt;,\n",
              ")</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters and corresponding accuracy\n",
        "best_params = grid_search.best_params_\n",
        "best_accuracy = grid_search.best_score_\n",
        "\n",
        "print(\"Best score: {:.3f}, \\nBest params: {}\".format(best_accuracy, best_params))"
      ],
      "metadata": {
        "id": "UmmiVt5Nab9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2714d7cc-9e5b-4158-e713-1e1300302979"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best score: 0.712, \n",
            "best params: {'clf__callbacks__EarlyStopping__patience': 5, 'clf__lr': 0.01, 'clf__module__nonlin': <function relu at 0x7d49601c0a60>, 'clf__module__num_units': 300, 'clf__optimizer': <class 'torch.optim.adam.Adam'>, 'vect__ngram_range': (1, 1)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the test accuracy with the best model\n",
        "test_accuracy = grid_search.score(X_test, y_t)\n",
        "\n",
        "print(f\"Best test accuracy: {test_accuracy:.3f}\")"
      ],
      "metadata": {
        "id": "vGPvT5QTo-RY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6888f767-9bcf-4ccf-d5fb-c2b8d2f53764"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best test accuracy: 0.714\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "bd97b8bffa4d3737e84826bc3d37be3046061822757ce35137ab82ad4c5a2016"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}